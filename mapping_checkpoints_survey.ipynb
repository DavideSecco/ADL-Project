{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6153ae",
   "metadata": {},
   "source": [
    "# Confronto e analisi fra model dictionaries dei diversi modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0feaca5",
   "metadata": {},
   "source": [
    "```\n",
    "UnOfficial DeCUR    --> form DenseDeCUR implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a6f388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in decur_state_dict_pth: dict_keys(['epoch', 'model', 'optimizer'])\n",
      "module.backbone_1.conv1.weight torch.Size([64, 3, 7, 7])\n",
      "module.backbone_1.bn1.weight torch.Size([64])\n",
      "module.backbone_1.bn1.bias torch.Size([64])\n",
      "module.backbone_1.bn1.running_mean torch.Size([64])\n",
      "module.backbone_1.bn1.running_var torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "### Load DeCUR checkpoint (.pth)\n",
    "decur_state_dict_pth = torch.load(\"DenseDeCUR/checkpoint/UnOfficial_DeCUR_from_lists/decur_checkpoint_0000.pth\", map_location=torch.device('cpu'), weights_only=True)\n",
    "\n",
    "# per KAROLINA dovrebbe essere questo\n",
    "# /mnt/proj3/eu-25-19/davide_secco/ADL-Project/DenseDeCUR/checkpoint/decur_checkpoint_0000.pth   DA CAMBIARE CON CKPT CORRETTO\n",
    "print(\"Keys in decur_state_dict_pth:\", decur_state_dict_pth.keys())\n",
    "\n",
    "# DeCUR model state_dict (estraggo solo il model)\n",
    "decur_model_state_dict = decur_state_dict_pth['model']\n",
    "\n",
    "for k in list(decur_model_state_dict)[:5]:\n",
    "    print(k, decur_model_state_dict[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494213f",
   "metadata": {},
   "source": [
    "```\n",
    "UnOfficial DenseCL    --> form DenseDeCUR implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6988f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in densecl_state_dict_pth: dict_keys(['epoch', 'model', 'optimizer'])\n",
      "module.queue torch.Size([128, 65536])\n",
      "module.queue_ptr torch.Size([1])\n",
      "module.queue2 torch.Size([128, 65536])\n",
      "module.queue2_ptr torch.Size([1])\n",
      "module.encoder_q.0.conv1.weight torch.Size([64, 3, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "### Load DenseCL checkpoint (.pth)\n",
    "densecl_state_dict_pth = torch.load(\"DenseDeCUR/checkpoint/UnOfficial_DenseCL_from_lists/decur_checkpoint_0000.pth\", map_location=torch.device('cpu'), weights_only=True)\n",
    "\n",
    "# per KAROLINA dovrebbe essere questo\n",
    "# /mnt/proj3/eu-25-19/davide_secco/ADL-Project/DenseDeCUR/checkpoint/decur_checkpoint_0000.pth   DA CAMBIARE CON CKPT CORRETTO \n",
    "\n",
    "print(\"Keys in densecl_state_dict_pth:\", densecl_state_dict_pth.keys())\n",
    "\n",
    "# DenseCL model state_dict (estraggo solo il model)\n",
    "densecl_model_state_dict = densecl_state_dict_pth['model']\n",
    "\n",
    "for k in list(densecl_model_state_dict)[:5]:\n",
    "    print(k, densecl_model_state_dict[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5071a450",
   "metadata": {},
   "source": [
    "```\n",
    "Official DenseDeCUR    --> form DenseDeCUR implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f320e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in densecur_state_dict_pth: dict_keys(['epoch', 'model', 'optimizer'])\n",
      "module.mod1.queue torch.Size([128, 65536])\n",
      "module.mod1.queue_ptr torch.Size([1])\n",
      "module.mod1.queue2 torch.Size([128, 65536])\n",
      "module.mod1.queue2_ptr torch.Size([1])\n",
      "module.mod1.encoder_q.0.conv1.weight torch.Size([64, 3, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "### Load DenseDeCUR checkpoint (.pth)\n",
    "densecur_state_dict_pth = torch.load(\"DenseDeCUR/checkpoint/Official_DenseDeCUR_from_lists/decur_checkpoint_0000.pth\", map_location=torch.device('cpu'), weights_only=True)\n",
    "\n",
    "# per KAROLINA dovrebbe essere questo\n",
    "# /mnt/proj3/eu-25-19/davide_secco/ADL-Project/DenseDeCUR/checkpoint/decur_checkpoint_0000.pth   ????   DA CAMBIARE CON CKPT CORRETTO \n",
    "\n",
    "print(\"Keys in densecur_state_dict_pth:\", densecur_state_dict_pth.keys())\n",
    "\n",
    "# DenseDeCUR model state_dict (estraggo solo il model)\n",
    "densecur_model_state_dict = densecur_state_dict_pth['model']\n",
    "\n",
    "for k in list(densecur_model_state_dict)[:5]:\n",
    "    print(k, densecur_model_state_dict[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5053e2f6",
   "metadata": {},
   "source": [
    "```\n",
    "ICAFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06e7caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in icafusion_model_state_dict: odict_keys(['model.0.layer.0.weight', 'model.0.layer.1.weight', 'model.0.layer.1.bias', 'model.0.layer.1.running_mean', 'model.0.layer.1.running_var', 'model.0.layer.1.num_batches_tracked', 'model.1.layer.0.conv1.weight', 'model.1.layer.0.bn1.weight', 'model.1.layer.0.bn1.bias', 'model.1.layer.0.bn1.running_mean', 'model.1.layer.0.bn1.running_var', 'model.1.layer.0.bn1.num_batches_tracked', 'model.1.layer.0.conv2.weight', 'model.1.layer.0.bn2.weight', 'model.1.layer.0.bn2.bias', 'model.1.layer.0.bn2.running_mean', 'model.1.layer.0.bn2.running_var', 'model.1.layer.0.bn2.num_batches_tracked', 'model.1.layer.0.conv3.weight', 'model.1.layer.0.bn3.weight', 'model.1.layer.0.bn3.bias', 'model.1.layer.0.bn3.running_mean', 'model.1.layer.0.bn3.running_var', 'model.1.layer.0.bn3.num_batches_tracked', 'model.1.layer.0.shortcut.0.weight', 'model.1.layer.0.shortcut.1.weight', 'model.1.layer.0.shortcut.1.bias', 'model.1.layer.0.shortcut.1.running_mean', 'model.1.layer.0.shortcut.1.running_var', 'model.1.layer.0.shortcut.1.num_batches_tracked', 'model.1.layer.1.conv1.weight', 'model.1.layer.1.bn1.weight', 'model.1.layer.1.bn1.bias', 'model.1.layer.1.bn1.running_mean', 'model.1.layer.1.bn1.running_var', 'model.1.layer.1.bn1.num_batches_tracked', 'model.1.layer.1.conv2.weight', 'model.1.layer.1.bn2.weight', 'model.1.layer.1.bn2.bias', 'model.1.layer.1.bn2.running_mean', 'model.1.layer.1.bn2.running_var', 'model.1.layer.1.bn2.num_batches_tracked', 'model.1.layer.1.conv3.weight', 'model.1.layer.1.bn3.weight', 'model.1.layer.1.bn3.bias', 'model.1.layer.1.bn3.running_mean', 'model.1.layer.1.bn3.running_var', 'model.1.layer.1.bn3.num_batches_tracked', 'model.1.layer.2.conv1.weight', 'model.1.layer.2.bn1.weight', 'model.1.layer.2.bn1.bias', 'model.1.layer.2.bn1.running_mean', 'model.1.layer.2.bn1.running_var', 'model.1.layer.2.bn1.num_batches_tracked', 'model.1.layer.2.conv2.weight', 'model.1.layer.2.bn2.weight', 'model.1.layer.2.bn2.bias', 'model.1.layer.2.bn2.running_mean', 'model.1.layer.2.bn2.running_var', 'model.1.layer.2.bn2.num_batches_tracked', 'model.1.layer.2.conv3.weight', 'model.1.layer.2.bn3.weight', 'model.1.layer.2.bn3.bias', 'model.1.layer.2.bn3.running_mean', 'model.1.layer.2.bn3.running_var', 'model.1.layer.2.bn3.num_batches_tracked', 'model.2.layer.0.conv1.weight', 'model.2.layer.0.bn1.weight', 'model.2.layer.0.bn1.bias', 'model.2.layer.0.bn1.running_mean', 'model.2.layer.0.bn1.running_var', 'model.2.layer.0.bn1.num_batches_tracked', 'model.2.layer.0.conv2.weight', 'model.2.layer.0.bn2.weight', 'model.2.layer.0.bn2.bias', 'model.2.layer.0.bn2.running_mean', 'model.2.layer.0.bn2.running_var', 'model.2.layer.0.bn2.num_batches_tracked', 'model.2.layer.0.conv3.weight', 'model.2.layer.0.bn3.weight', 'model.2.layer.0.bn3.bias', 'model.2.layer.0.bn3.running_mean', 'model.2.layer.0.bn3.running_var', 'model.2.layer.0.bn3.num_batches_tracked', 'model.2.layer.0.shortcut.0.weight', 'model.2.layer.0.shortcut.1.weight', 'model.2.layer.0.shortcut.1.bias', 'model.2.layer.0.shortcut.1.running_mean', 'model.2.layer.0.shortcut.1.running_var', 'model.2.layer.0.shortcut.1.num_batches_tracked', 'model.2.layer.1.conv1.weight', 'model.2.layer.1.bn1.weight', 'model.2.layer.1.bn1.bias', 'model.2.layer.1.bn1.running_mean', 'model.2.layer.1.bn1.running_var', 'model.2.layer.1.bn1.num_batches_tracked', 'model.2.layer.1.conv2.weight', 'model.2.layer.1.bn2.weight', 'model.2.layer.1.bn2.bias', 'model.2.layer.1.bn2.running_mean', 'model.2.layer.1.bn2.running_var', 'model.2.layer.1.bn2.num_batches_tracked', 'model.2.layer.1.conv3.weight', 'model.2.layer.1.bn3.weight', 'model.2.layer.1.bn3.bias', 'model.2.layer.1.bn3.running_mean', 'model.2.layer.1.bn3.running_var', 'model.2.layer.1.bn3.num_batches_tracked', 'model.2.layer.2.conv1.weight', 'model.2.layer.2.bn1.weight', 'model.2.layer.2.bn1.bias', 'model.2.layer.2.bn1.running_mean', 'model.2.layer.2.bn1.running_var', 'model.2.layer.2.bn1.num_batches_tracked', 'model.2.layer.2.conv2.weight', 'model.2.layer.2.bn2.weight', 'model.2.layer.2.bn2.bias', 'model.2.layer.2.bn2.running_mean', 'model.2.layer.2.bn2.running_var', 'model.2.layer.2.bn2.num_batches_tracked', 'model.2.layer.2.conv3.weight', 'model.2.layer.2.bn3.weight', 'model.2.layer.2.bn3.bias', 'model.2.layer.2.bn3.running_mean', 'model.2.layer.2.bn3.running_var', 'model.2.layer.2.bn3.num_batches_tracked', 'model.2.layer.3.conv1.weight', 'model.2.layer.3.bn1.weight', 'model.2.layer.3.bn1.bias', 'model.2.layer.3.bn1.running_mean', 'model.2.layer.3.bn1.running_var', 'model.2.layer.3.bn1.num_batches_tracked', 'model.2.layer.3.conv2.weight', 'model.2.layer.3.bn2.weight', 'model.2.layer.3.bn2.bias', 'model.2.layer.3.bn2.running_mean', 'model.2.layer.3.bn2.running_var', 'model.2.layer.3.bn2.num_batches_tracked', 'model.2.layer.3.conv3.weight', 'model.2.layer.3.bn3.weight', 'model.2.layer.3.bn3.bias', 'model.2.layer.3.bn3.running_mean', 'model.2.layer.3.bn3.running_var', 'model.2.layer.3.bn3.num_batches_tracked', 'model.3.layer.0.conv1.weight', 'model.3.layer.0.bn1.weight', 'model.3.layer.0.bn1.bias', 'model.3.layer.0.bn1.running_mean', 'model.3.layer.0.bn1.running_var', 'model.3.layer.0.bn1.num_batches_tracked', 'model.3.layer.0.conv2.weight', 'model.3.layer.0.bn2.weight', 'model.3.layer.0.bn2.bias', 'model.3.layer.0.bn2.running_mean', 'model.3.layer.0.bn2.running_var', 'model.3.layer.0.bn2.num_batches_tracked', 'model.3.layer.0.conv3.weight', 'model.3.layer.0.bn3.weight', 'model.3.layer.0.bn3.bias', 'model.3.layer.0.bn3.running_mean', 'model.3.layer.0.bn3.running_var', 'model.3.layer.0.bn3.num_batches_tracked', 'model.3.layer.0.shortcut.0.weight', 'model.3.layer.0.shortcut.1.weight', 'model.3.layer.0.shortcut.1.bias', 'model.3.layer.0.shortcut.1.running_mean', 'model.3.layer.0.shortcut.1.running_var', 'model.3.layer.0.shortcut.1.num_batches_tracked', 'model.3.layer.1.conv1.weight', 'model.3.layer.1.bn1.weight', 'model.3.layer.1.bn1.bias', 'model.3.layer.1.bn1.running_mean', 'model.3.layer.1.bn1.running_var', 'model.3.layer.1.bn1.num_batches_tracked', 'model.3.layer.1.conv2.weight', 'model.3.layer.1.bn2.weight', 'model.3.layer.1.bn2.bias', 'model.3.layer.1.bn2.running_mean', 'model.3.layer.1.bn2.running_var', 'model.3.layer.1.bn2.num_batches_tracked', 'model.3.layer.1.conv3.weight', 'model.3.layer.1.bn3.weight', 'model.3.layer.1.bn3.bias', 'model.3.layer.1.bn3.running_mean', 'model.3.layer.1.bn3.running_var', 'model.3.layer.1.bn3.num_batches_tracked', 'model.3.layer.2.conv1.weight', 'model.3.layer.2.bn1.weight', 'model.3.layer.2.bn1.bias', 'model.3.layer.2.bn1.running_mean', 'model.3.layer.2.bn1.running_var', 'model.3.layer.2.bn1.num_batches_tracked', 'model.3.layer.2.conv2.weight', 'model.3.layer.2.bn2.weight', 'model.3.layer.2.bn2.bias', 'model.3.layer.2.bn2.running_mean', 'model.3.layer.2.bn2.running_var', 'model.3.layer.2.bn2.num_batches_tracked', 'model.3.layer.2.conv3.weight', 'model.3.layer.2.bn3.weight', 'model.3.layer.2.bn3.bias', 'model.3.layer.2.bn3.running_mean', 'model.3.layer.2.bn3.running_var', 'model.3.layer.2.bn3.num_batches_tracked', 'model.3.layer.3.conv1.weight', 'model.3.layer.3.bn1.weight', 'model.3.layer.3.bn1.bias', 'model.3.layer.3.bn1.running_mean', 'model.3.layer.3.bn1.running_var', 'model.3.layer.3.bn1.num_batches_tracked', 'model.3.layer.3.conv2.weight', 'model.3.layer.3.bn2.weight', 'model.3.layer.3.bn2.bias', 'model.3.layer.3.bn2.running_mean', 'model.3.layer.3.bn2.running_var', 'model.3.layer.3.bn2.num_batches_tracked', 'model.3.layer.3.conv3.weight', 'model.3.layer.3.bn3.weight', 'model.3.layer.3.bn3.bias', 'model.3.layer.3.bn3.running_mean', 'model.3.layer.3.bn3.running_var', 'model.3.layer.3.bn3.num_batches_tracked', 'model.3.layer.4.conv1.weight', 'model.3.layer.4.bn1.weight', 'model.3.layer.4.bn1.bias', 'model.3.layer.4.bn1.running_mean', 'model.3.layer.4.bn1.running_var', 'model.3.layer.4.bn1.num_batches_tracked', 'model.3.layer.4.conv2.weight', 'model.3.layer.4.bn2.weight', 'model.3.layer.4.bn2.bias', 'model.3.layer.4.bn2.running_mean', 'model.3.layer.4.bn2.running_var', 'model.3.layer.4.bn2.num_batches_tracked', 'model.3.layer.4.conv3.weight', 'model.3.layer.4.bn3.weight', 'model.3.layer.4.bn3.bias', 'model.3.layer.4.bn3.running_mean', 'model.3.layer.4.bn3.running_var', 'model.3.layer.4.bn3.num_batches_tracked', 'model.3.layer.5.conv1.weight', 'model.3.layer.5.bn1.weight', 'model.3.layer.5.bn1.bias', 'model.3.layer.5.bn1.running_mean', 'model.3.layer.5.bn1.running_var', 'model.3.layer.5.bn1.num_batches_tracked', 'model.3.layer.5.conv2.weight', 'model.3.layer.5.bn2.weight', 'model.3.layer.5.bn2.bias', 'model.3.layer.5.bn2.running_mean', 'model.3.layer.5.bn2.running_var', 'model.3.layer.5.bn2.num_batches_tracked', 'model.3.layer.5.conv3.weight', 'model.3.layer.5.bn3.weight', 'model.3.layer.5.bn3.bias', 'model.3.layer.5.bn3.running_mean', 'model.3.layer.5.bn3.running_var', 'model.3.layer.5.bn3.num_batches_tracked', 'model.4.layer.0.conv1.weight', 'model.4.layer.0.bn1.weight', 'model.4.layer.0.bn1.bias', 'model.4.layer.0.bn1.running_mean', 'model.4.layer.0.bn1.running_var', 'model.4.layer.0.bn1.num_batches_tracked', 'model.4.layer.0.conv2.weight', 'model.4.layer.0.bn2.weight', 'model.4.layer.0.bn2.bias', 'model.4.layer.0.bn2.running_mean', 'model.4.layer.0.bn2.running_var', 'model.4.layer.0.bn2.num_batches_tracked', 'model.4.layer.0.conv3.weight', 'model.4.layer.0.bn3.weight', 'model.4.layer.0.bn3.bias', 'model.4.layer.0.bn3.running_mean', 'model.4.layer.0.bn3.running_var', 'model.4.layer.0.bn3.num_batches_tracked', 'model.4.layer.0.shortcut.0.weight', 'model.4.layer.0.shortcut.1.weight', 'model.4.layer.0.shortcut.1.bias', 'model.4.layer.0.shortcut.1.running_mean', 'model.4.layer.0.shortcut.1.running_var', 'model.4.layer.0.shortcut.1.num_batches_tracked', 'model.4.layer.1.conv1.weight', 'model.4.layer.1.bn1.weight', 'model.4.layer.1.bn1.bias', 'model.4.layer.1.bn1.running_mean', 'model.4.layer.1.bn1.running_var', 'model.4.layer.1.bn1.num_batches_tracked', 'model.4.layer.1.conv2.weight', 'model.4.layer.1.bn2.weight', 'model.4.layer.1.bn2.bias', 'model.4.layer.1.bn2.running_mean', 'model.4.layer.1.bn2.running_var', 'model.4.layer.1.bn2.num_batches_tracked', 'model.4.layer.1.conv3.weight', 'model.4.layer.1.bn3.weight', 'model.4.layer.1.bn3.bias', 'model.4.layer.1.bn3.running_mean', 'model.4.layer.1.bn3.running_var', 'model.4.layer.1.bn3.num_batches_tracked', 'model.4.layer.2.conv1.weight', 'model.4.layer.2.bn1.weight', 'model.4.layer.2.bn1.bias', 'model.4.layer.2.bn1.running_mean', 'model.4.layer.2.bn1.running_var', 'model.4.layer.2.bn1.num_batches_tracked', 'model.4.layer.2.conv2.weight', 'model.4.layer.2.bn2.weight', 'model.4.layer.2.bn2.bias', 'model.4.layer.2.bn2.running_mean', 'model.4.layer.2.bn2.running_var', 'model.4.layer.2.bn2.num_batches_tracked', 'model.4.layer.2.conv3.weight', 'model.4.layer.2.bn3.weight', 'model.4.layer.2.bn3.bias', 'model.4.layer.2.bn3.running_mean', 'model.4.layer.2.bn3.running_var', 'model.4.layer.2.bn3.num_batches_tracked', 'model.5.layer.0.weight', 'model.5.layer.1.weight', 'model.5.layer.1.bias', 'model.5.layer.1.running_mean', 'model.5.layer.1.running_var', 'model.5.layer.1.num_batches_tracked', 'model.6.layer.0.conv1.weight', 'model.6.layer.0.bn1.weight', 'model.6.layer.0.bn1.bias', 'model.6.layer.0.bn1.running_mean', 'model.6.layer.0.bn1.running_var', 'model.6.layer.0.bn1.num_batches_tracked', 'model.6.layer.0.conv2.weight', 'model.6.layer.0.bn2.weight', 'model.6.layer.0.bn2.bias', 'model.6.layer.0.bn2.running_mean', 'model.6.layer.0.bn2.running_var', 'model.6.layer.0.bn2.num_batches_tracked', 'model.6.layer.0.conv3.weight', 'model.6.layer.0.bn3.weight', 'model.6.layer.0.bn3.bias', 'model.6.layer.0.bn3.running_mean', 'model.6.layer.0.bn3.running_var', 'model.6.layer.0.bn3.num_batches_tracked', 'model.6.layer.0.shortcut.0.weight', 'model.6.layer.0.shortcut.1.weight', 'model.6.layer.0.shortcut.1.bias', 'model.6.layer.0.shortcut.1.running_mean', 'model.6.layer.0.shortcut.1.running_var', 'model.6.layer.0.shortcut.1.num_batches_tracked', 'model.6.layer.1.conv1.weight', 'model.6.layer.1.bn1.weight', 'model.6.layer.1.bn1.bias', 'model.6.layer.1.bn1.running_mean', 'model.6.layer.1.bn1.running_var', 'model.6.layer.1.bn1.num_batches_tracked', 'model.6.layer.1.conv2.weight', 'model.6.layer.1.bn2.weight', 'model.6.layer.1.bn2.bias', 'model.6.layer.1.bn2.running_mean', 'model.6.layer.1.bn2.running_var', 'model.6.layer.1.bn2.num_batches_tracked', 'model.6.layer.1.conv3.weight', 'model.6.layer.1.bn3.weight', 'model.6.layer.1.bn3.bias', 'model.6.layer.1.bn3.running_mean', 'model.6.layer.1.bn3.running_var', 'model.6.layer.1.bn3.num_batches_tracked', 'model.6.layer.2.conv1.weight', 'model.6.layer.2.bn1.weight', 'model.6.layer.2.bn1.bias', 'model.6.layer.2.bn1.running_mean', 'model.6.layer.2.bn1.running_var', 'model.6.layer.2.bn1.num_batches_tracked', 'model.6.layer.2.conv2.weight', 'model.6.layer.2.bn2.weight', 'model.6.layer.2.bn2.bias', 'model.6.layer.2.bn2.running_mean', 'model.6.layer.2.bn2.running_var', 'model.6.layer.2.bn2.num_batches_tracked', 'model.6.layer.2.conv3.weight', 'model.6.layer.2.bn3.weight', 'model.6.layer.2.bn3.bias', 'model.6.layer.2.bn3.running_mean', 'model.6.layer.2.bn3.running_var', 'model.6.layer.2.bn3.num_batches_tracked', 'model.7.layer.0.conv1.weight', 'model.7.layer.0.bn1.weight', 'model.7.layer.0.bn1.bias', 'model.7.layer.0.bn1.running_mean', 'model.7.layer.0.bn1.running_var', 'model.7.layer.0.bn1.num_batches_tracked', 'model.7.layer.0.conv2.weight', 'model.7.layer.0.bn2.weight', 'model.7.layer.0.bn2.bias', 'model.7.layer.0.bn2.running_mean', 'model.7.layer.0.bn2.running_var', 'model.7.layer.0.bn2.num_batches_tracked', 'model.7.layer.0.conv3.weight', 'model.7.layer.0.bn3.weight', 'model.7.layer.0.bn3.bias', 'model.7.layer.0.bn3.running_mean', 'model.7.layer.0.bn3.running_var', 'model.7.layer.0.bn3.num_batches_tracked', 'model.7.layer.0.shortcut.0.weight', 'model.7.layer.0.shortcut.1.weight', 'model.7.layer.0.shortcut.1.bias', 'model.7.layer.0.shortcut.1.running_mean', 'model.7.layer.0.shortcut.1.running_var', 'model.7.layer.0.shortcut.1.num_batches_tracked', 'model.7.layer.1.conv1.weight', 'model.7.layer.1.bn1.weight', 'model.7.layer.1.bn1.bias', 'model.7.layer.1.bn1.running_mean', 'model.7.layer.1.bn1.running_var', 'model.7.layer.1.bn1.num_batches_tracked', 'model.7.layer.1.conv2.weight', 'model.7.layer.1.bn2.weight', 'model.7.layer.1.bn2.bias', 'model.7.layer.1.bn2.running_mean', 'model.7.layer.1.bn2.running_var', 'model.7.layer.1.bn2.num_batches_tracked', 'model.7.layer.1.conv3.weight', 'model.7.layer.1.bn3.weight', 'model.7.layer.1.bn3.bias', 'model.7.layer.1.bn3.running_mean', 'model.7.layer.1.bn3.running_var', 'model.7.layer.1.bn3.num_batches_tracked', 'model.7.layer.2.conv1.weight', 'model.7.layer.2.bn1.weight', 'model.7.layer.2.bn1.bias', 'model.7.layer.2.bn1.running_mean', 'model.7.layer.2.bn1.running_var', 'model.7.layer.2.bn1.num_batches_tracked', 'model.7.layer.2.conv2.weight', 'model.7.layer.2.bn2.weight', 'model.7.layer.2.bn2.bias', 'model.7.layer.2.bn2.running_mean', 'model.7.layer.2.bn2.running_var', 'model.7.layer.2.bn2.num_batches_tracked', 'model.7.layer.2.conv3.weight', 'model.7.layer.2.bn3.weight', 'model.7.layer.2.bn3.bias', 'model.7.layer.2.bn3.running_mean', 'model.7.layer.2.bn3.running_var', 'model.7.layer.2.bn3.num_batches_tracked', 'model.7.layer.3.conv1.weight', 'model.7.layer.3.bn1.weight', 'model.7.layer.3.bn1.bias', 'model.7.layer.3.bn1.running_mean', 'model.7.layer.3.bn1.running_var', 'model.7.layer.3.bn1.num_batches_tracked', 'model.7.layer.3.conv2.weight', 'model.7.layer.3.bn2.weight', 'model.7.layer.3.bn2.bias', 'model.7.layer.3.bn2.running_mean', 'model.7.layer.3.bn2.running_var', 'model.7.layer.3.bn2.num_batches_tracked', 'model.7.layer.3.conv3.weight', 'model.7.layer.3.bn3.weight', 'model.7.layer.3.bn3.bias', 'model.7.layer.3.bn3.running_mean', 'model.7.layer.3.bn3.running_var', 'model.7.layer.3.bn3.num_batches_tracked', 'model.8.layer.0.conv1.weight', 'model.8.layer.0.bn1.weight', 'model.8.layer.0.bn1.bias', 'model.8.layer.0.bn1.running_mean', 'model.8.layer.0.bn1.running_var', 'model.8.layer.0.bn1.num_batches_tracked', 'model.8.layer.0.conv2.weight', 'model.8.layer.0.bn2.weight', 'model.8.layer.0.bn2.bias', 'model.8.layer.0.bn2.running_mean', 'model.8.layer.0.bn2.running_var', 'model.8.layer.0.bn2.num_batches_tracked', 'model.8.layer.0.conv3.weight', 'model.8.layer.0.bn3.weight', 'model.8.layer.0.bn3.bias', 'model.8.layer.0.bn3.running_mean', 'model.8.layer.0.bn3.running_var', 'model.8.layer.0.bn3.num_batches_tracked', 'model.8.layer.0.shortcut.0.weight', 'model.8.layer.0.shortcut.1.weight', 'model.8.layer.0.shortcut.1.bias', 'model.8.layer.0.shortcut.1.running_mean', 'model.8.layer.0.shortcut.1.running_var', 'model.8.layer.0.shortcut.1.num_batches_tracked', 'model.8.layer.1.conv1.weight', 'model.8.layer.1.bn1.weight', 'model.8.layer.1.bn1.bias', 'model.8.layer.1.bn1.running_mean', 'model.8.layer.1.bn1.running_var', 'model.8.layer.1.bn1.num_batches_tracked', 'model.8.layer.1.conv2.weight', 'model.8.layer.1.bn2.weight', 'model.8.layer.1.bn2.bias', 'model.8.layer.1.bn2.running_mean', 'model.8.layer.1.bn2.running_var', 'model.8.layer.1.bn2.num_batches_tracked', 'model.8.layer.1.conv3.weight', 'model.8.layer.1.bn3.weight', 'model.8.layer.1.bn3.bias', 'model.8.layer.1.bn3.running_mean', 'model.8.layer.1.bn3.running_var', 'model.8.layer.1.bn3.num_batches_tracked', 'model.8.layer.2.conv1.weight', 'model.8.layer.2.bn1.weight', 'model.8.layer.2.bn1.bias', 'model.8.layer.2.bn1.running_mean', 'model.8.layer.2.bn1.running_var', 'model.8.layer.2.bn1.num_batches_tracked', 'model.8.layer.2.conv2.weight', 'model.8.layer.2.bn2.weight', 'model.8.layer.2.bn2.bias', 'model.8.layer.2.bn2.running_mean', 'model.8.layer.2.bn2.running_var', 'model.8.layer.2.bn2.num_batches_tracked', 'model.8.layer.2.conv3.weight', 'model.8.layer.2.bn3.weight', 'model.8.layer.2.bn3.bias', 'model.8.layer.2.bn3.running_mean', 'model.8.layer.2.bn3.running_var', 'model.8.layer.2.bn3.num_batches_tracked', 'model.8.layer.3.conv1.weight', 'model.8.layer.3.bn1.weight', 'model.8.layer.3.bn1.bias', 'model.8.layer.3.bn1.running_mean', 'model.8.layer.3.bn1.running_var', 'model.8.layer.3.bn1.num_batches_tracked', 'model.8.layer.3.conv2.weight', 'model.8.layer.3.bn2.weight', 'model.8.layer.3.bn2.bias', 'model.8.layer.3.bn2.running_mean', 'model.8.layer.3.bn2.running_var', 'model.8.layer.3.bn2.num_batches_tracked', 'model.8.layer.3.conv3.weight', 'model.8.layer.3.bn3.weight', 'model.8.layer.3.bn3.bias', 'model.8.layer.3.bn3.running_mean', 'model.8.layer.3.bn3.running_var', 'model.8.layer.3.bn3.num_batches_tracked', 'model.8.layer.4.conv1.weight', 'model.8.layer.4.bn1.weight', 'model.8.layer.4.bn1.bias', 'model.8.layer.4.bn1.running_mean', 'model.8.layer.4.bn1.running_var', 'model.8.layer.4.bn1.num_batches_tracked', 'model.8.layer.4.conv2.weight', 'model.8.layer.4.bn2.weight', 'model.8.layer.4.bn2.bias', 'model.8.layer.4.bn2.running_mean', 'model.8.layer.4.bn2.running_var', 'model.8.layer.4.bn2.num_batches_tracked', 'model.8.layer.4.conv3.weight', 'model.8.layer.4.bn3.weight', 'model.8.layer.4.bn3.bias', 'model.8.layer.4.bn3.running_mean', 'model.8.layer.4.bn3.running_var', 'model.8.layer.4.bn3.num_batches_tracked', 'model.8.layer.5.conv1.weight', 'model.8.layer.5.bn1.weight', 'model.8.layer.5.bn1.bias', 'model.8.layer.5.bn1.running_mean', 'model.8.layer.5.bn1.running_var', 'model.8.layer.5.bn1.num_batches_tracked', 'model.8.layer.5.conv2.weight', 'model.8.layer.5.bn2.weight', 'model.8.layer.5.bn2.bias', 'model.8.layer.5.bn2.running_mean', 'model.8.layer.5.bn2.running_var', 'model.8.layer.5.bn2.num_batches_tracked', 'model.8.layer.5.conv3.weight', 'model.8.layer.5.bn3.weight', 'model.8.layer.5.bn3.bias', 'model.8.layer.5.bn3.running_mean', 'model.8.layer.5.bn3.running_var', 'model.8.layer.5.bn3.num_batches_tracked', 'model.9.layer.0.conv1.weight', 'model.9.layer.0.bn1.weight', 'model.9.layer.0.bn1.bias', 'model.9.layer.0.bn1.running_mean', 'model.9.layer.0.bn1.running_var', 'model.9.layer.0.bn1.num_batches_tracked', 'model.9.layer.0.conv2.weight', 'model.9.layer.0.bn2.weight', 'model.9.layer.0.bn2.bias', 'model.9.layer.0.bn2.running_mean', 'model.9.layer.0.bn2.running_var', 'model.9.layer.0.bn2.num_batches_tracked', 'model.9.layer.0.conv3.weight', 'model.9.layer.0.bn3.weight', 'model.9.layer.0.bn3.bias', 'model.9.layer.0.bn3.running_mean', 'model.9.layer.0.bn3.running_var', 'model.9.layer.0.bn3.num_batches_tracked', 'model.9.layer.0.shortcut.0.weight', 'model.9.layer.0.shortcut.1.weight', 'model.9.layer.0.shortcut.1.bias', 'model.9.layer.0.shortcut.1.running_mean', 'model.9.layer.0.shortcut.1.running_var', 'model.9.layer.0.shortcut.1.num_batches_tracked', 'model.9.layer.1.conv1.weight', 'model.9.layer.1.bn1.weight', 'model.9.layer.1.bn1.bias', 'model.9.layer.1.bn1.running_mean', 'model.9.layer.1.bn1.running_var', 'model.9.layer.1.bn1.num_batches_tracked', 'model.9.layer.1.conv2.weight', 'model.9.layer.1.bn2.weight', 'model.9.layer.1.bn2.bias', 'model.9.layer.1.bn2.running_mean', 'model.9.layer.1.bn2.running_var', 'model.9.layer.1.bn2.num_batches_tracked', 'model.9.layer.1.conv3.weight', 'model.9.layer.1.bn3.weight', 'model.9.layer.1.bn3.bias', 'model.9.layer.1.bn3.running_mean', 'model.9.layer.1.bn3.running_var', 'model.9.layer.1.bn3.num_batches_tracked', 'model.9.layer.2.conv1.weight', 'model.9.layer.2.bn1.weight', 'model.9.layer.2.bn1.bias', 'model.9.layer.2.bn1.running_mean', 'model.9.layer.2.bn1.running_var', 'model.9.layer.2.bn1.num_batches_tracked', 'model.9.layer.2.conv2.weight', 'model.9.layer.2.bn2.weight', 'model.9.layer.2.bn2.bias', 'model.9.layer.2.bn2.running_mean', 'model.9.layer.2.bn2.running_var', 'model.9.layer.2.bn2.num_batches_tracked', 'model.9.layer.2.conv3.weight', 'model.9.layer.2.bn3.weight', 'model.9.layer.2.bn3.bias', 'model.9.layer.2.bn3.running_mean', 'model.9.layer.2.bn3.running_var', 'model.9.layer.2.bn3.num_batches_tracked', 'model.10.pos_emb_vis', 'model.10.pos_emb_ir', 'model.10.vis_coefficient.w1', 'model.10.vis_coefficient.w2', 'model.10.ir_coefficient.w1', 'model.10.ir_coefficient.w2', 'model.10.crosstransformer.0.ln_input.weight', 'model.10.crosstransformer.0.ln_input.bias', 'model.10.crosstransformer.0.ln_output.weight', 'model.10.crosstransformer.0.ln_output.bias', 'model.10.crosstransformer.0.crossatt.que_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.que_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.key_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.key_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.val_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.val_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.que_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.que_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.key_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.key_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.val_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.val_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.out_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.out_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.out_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.out_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.LN1.weight', 'model.10.crosstransformer.0.crossatt.LN1.bias', 'model.10.crosstransformer.0.crossatt.LN2.weight', 'model.10.crosstransformer.0.crossatt.LN2.bias', 'model.10.crosstransformer.0.mlp_vis.0.weight', 'model.10.crosstransformer.0.mlp_vis.0.bias', 'model.10.crosstransformer.0.mlp_vis.2.weight', 'model.10.crosstransformer.0.mlp_vis.2.bias', 'model.10.crosstransformer.0.mlp_ir.0.weight', 'model.10.crosstransformer.0.mlp_ir.0.bias', 'model.10.crosstransformer.0.mlp_ir.2.weight', 'model.10.crosstransformer.0.mlp_ir.2.bias', 'model.10.crosstransformer.0.mlp.0.weight', 'model.10.crosstransformer.0.mlp.0.bias', 'model.10.crosstransformer.0.mlp.2.weight', 'model.10.crosstransformer.0.mlp.2.bias', 'model.10.crosstransformer.0.LN1.weight', 'model.10.crosstransformer.0.LN1.bias', 'model.10.crosstransformer.0.LN2.weight', 'model.10.crosstransformer.0.LN2.bias', 'model.10.crosstransformer.0.coefficient1.bias', 'model.10.crosstransformer.0.coefficient2.bias', 'model.10.crosstransformer.0.coefficient3.bias', 'model.10.crosstransformer.0.coefficient4.bias', 'model.10.crosstransformer.0.coefficient5.bias', 'model.10.crosstransformer.0.coefficient6.bias', 'model.10.crosstransformer.0.coefficient7.bias', 'model.10.crosstransformer.0.coefficient8.bias', 'model.10.conv1x1_out.conv.weight', 'model.10.conv1x1_out.bn.weight', 'model.10.conv1x1_out.bn.bias', 'model.10.conv1x1_out.bn.running_mean', 'model.10.conv1x1_out.bn.running_var', 'model.10.conv1x1_out.bn.num_batches_tracked', 'model.11.pos_emb_vis', 'model.11.pos_emb_ir', 'model.11.vis_coefficient.w1', 'model.11.vis_coefficient.w2', 'model.11.ir_coefficient.w1', 'model.11.ir_coefficient.w2', 'model.11.crosstransformer.0.ln_input.weight', 'model.11.crosstransformer.0.ln_input.bias', 'model.11.crosstransformer.0.ln_output.weight', 'model.11.crosstransformer.0.ln_output.bias', 'model.11.crosstransformer.0.crossatt.que_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.que_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.key_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.key_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.val_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.val_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.que_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.que_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.key_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.key_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.val_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.val_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.out_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.out_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.out_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.out_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.LN1.weight', 'model.11.crosstransformer.0.crossatt.LN1.bias', 'model.11.crosstransformer.0.crossatt.LN2.weight', 'model.11.crosstransformer.0.crossatt.LN2.bias', 'model.11.crosstransformer.0.mlp_vis.0.weight', 'model.11.crosstransformer.0.mlp_vis.0.bias', 'model.11.crosstransformer.0.mlp_vis.2.weight', 'model.11.crosstransformer.0.mlp_vis.2.bias', 'model.11.crosstransformer.0.mlp_ir.0.weight', 'model.11.crosstransformer.0.mlp_ir.0.bias', 'model.11.crosstransformer.0.mlp_ir.2.weight', 'model.11.crosstransformer.0.mlp_ir.2.bias', 'model.11.crosstransformer.0.mlp.0.weight', 'model.11.crosstransformer.0.mlp.0.bias', 'model.11.crosstransformer.0.mlp.2.weight', 'model.11.crosstransformer.0.mlp.2.bias', 'model.11.crosstransformer.0.LN1.weight', 'model.11.crosstransformer.0.LN1.bias', 'model.11.crosstransformer.0.LN2.weight', 'model.11.crosstransformer.0.LN2.bias', 'model.11.crosstransformer.0.coefficient1.bias', 'model.11.crosstransformer.0.coefficient2.bias', 'model.11.crosstransformer.0.coefficient3.bias', 'model.11.crosstransformer.0.coefficient4.bias', 'model.11.crosstransformer.0.coefficient5.bias', 'model.11.crosstransformer.0.coefficient6.bias', 'model.11.crosstransformer.0.coefficient7.bias', 'model.11.crosstransformer.0.coefficient8.bias', 'model.11.conv1x1_out.conv.weight', 'model.11.conv1x1_out.bn.weight', 'model.11.conv1x1_out.bn.bias', 'model.11.conv1x1_out.bn.running_mean', 'model.11.conv1x1_out.bn.running_var', 'model.11.conv1x1_out.bn.num_batches_tracked', 'model.12.pos_emb_vis', 'model.12.pos_emb_ir', 'model.12.vis_coefficient.w1', 'model.12.vis_coefficient.w2', 'model.12.ir_coefficient.w1', 'model.12.ir_coefficient.w2', 'model.12.crosstransformer.0.ln_input.weight', 'model.12.crosstransformer.0.ln_input.bias', 'model.12.crosstransformer.0.ln_output.weight', 'model.12.crosstransformer.0.ln_output.bias', 'model.12.crosstransformer.0.crossatt.que_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.que_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.key_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.key_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.val_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.val_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.que_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.que_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.key_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.key_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.val_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.val_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.out_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.out_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.out_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.out_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.LN1.weight', 'model.12.crosstransformer.0.crossatt.LN1.bias', 'model.12.crosstransformer.0.crossatt.LN2.weight', 'model.12.crosstransformer.0.crossatt.LN2.bias', 'model.12.crosstransformer.0.mlp_vis.0.weight', 'model.12.crosstransformer.0.mlp_vis.0.bias', 'model.12.crosstransformer.0.mlp_vis.2.weight', 'model.12.crosstransformer.0.mlp_vis.2.bias', 'model.12.crosstransformer.0.mlp_ir.0.weight', 'model.12.crosstransformer.0.mlp_ir.0.bias', 'model.12.crosstransformer.0.mlp_ir.2.weight', 'model.12.crosstransformer.0.mlp_ir.2.bias', 'model.12.crosstransformer.0.mlp.0.weight', 'model.12.crosstransformer.0.mlp.0.bias', 'model.12.crosstransformer.0.mlp.2.weight', 'model.12.crosstransformer.0.mlp.2.bias', 'model.12.crosstransformer.0.LN1.weight', 'model.12.crosstransformer.0.LN1.bias', 'model.12.crosstransformer.0.LN2.weight', 'model.12.crosstransformer.0.LN2.bias', 'model.12.crosstransformer.0.coefficient1.bias', 'model.12.crosstransformer.0.coefficient2.bias', 'model.12.crosstransformer.0.coefficient3.bias', 'model.12.crosstransformer.0.coefficient4.bias', 'model.12.crosstransformer.0.coefficient5.bias', 'model.12.crosstransformer.0.coefficient6.bias', 'model.12.crosstransformer.0.coefficient7.bias', 'model.12.crosstransformer.0.coefficient8.bias', 'model.12.conv1x1_out.conv.weight', 'model.12.conv1x1_out.bn.weight', 'model.12.conv1x1_out.bn.bias', 'model.12.conv1x1_out.bn.running_mean', 'model.12.conv1x1_out.bn.running_var', 'model.12.conv1x1_out.bn.num_batches_tracked', 'model.13.conv.weight', 'model.13.bn.weight', 'model.13.bn.bias', 'model.13.bn.running_mean', 'model.13.bn.running_var', 'model.13.bn.num_batches_tracked', 'model.16.cv1.conv.weight', 'model.16.cv1.bn.weight', 'model.16.cv1.bn.bias', 'model.16.cv1.bn.running_mean', 'model.16.cv1.bn.running_var', 'model.16.cv1.bn.num_batches_tracked', 'model.16.cv2.conv.weight', 'model.16.cv2.bn.weight', 'model.16.cv2.bn.bias', 'model.16.cv2.bn.running_mean', 'model.16.cv2.bn.running_var', 'model.16.cv2.bn.num_batches_tracked', 'model.16.cv3.conv.weight', 'model.16.cv3.bn.weight', 'model.16.cv3.bn.bias', 'model.16.cv3.bn.running_mean', 'model.16.cv3.bn.running_var', 'model.16.cv3.bn.num_batches_tracked', 'model.16.m.0.cv1.conv.weight', 'model.16.m.0.cv1.bn.weight', 'model.16.m.0.cv1.bn.bias', 'model.16.m.0.cv1.bn.running_mean', 'model.16.m.0.cv1.bn.running_var', 'model.16.m.0.cv1.bn.num_batches_tracked', 'model.16.m.0.cv2.conv.weight', 'model.16.m.0.cv2.bn.weight', 'model.16.m.0.cv2.bn.bias', 'model.16.m.0.cv2.bn.running_mean', 'model.16.m.0.cv2.bn.running_var', 'model.16.m.0.cv2.bn.num_batches_tracked', 'model.16.m.1.cv1.conv.weight', 'model.16.m.1.cv1.bn.weight', 'model.16.m.1.cv1.bn.bias', 'model.16.m.1.cv1.bn.running_mean', 'model.16.m.1.cv1.bn.running_var', 'model.16.m.1.cv1.bn.num_batches_tracked', 'model.16.m.1.cv2.conv.weight', 'model.16.m.1.cv2.bn.weight', 'model.16.m.1.cv2.bn.bias', 'model.16.m.1.cv2.bn.running_mean', 'model.16.m.1.cv2.bn.running_var', 'model.16.m.1.cv2.bn.num_batches_tracked', 'model.16.m.2.cv1.conv.weight', 'model.16.m.2.cv1.bn.weight', 'model.16.m.2.cv1.bn.bias', 'model.16.m.2.cv1.bn.running_mean', 'model.16.m.2.cv1.bn.running_var', 'model.16.m.2.cv1.bn.num_batches_tracked', 'model.16.m.2.cv2.conv.weight', 'model.16.m.2.cv2.bn.weight', 'model.16.m.2.cv2.bn.bias', 'model.16.m.2.cv2.bn.running_mean', 'model.16.m.2.cv2.bn.running_var', 'model.16.m.2.cv2.bn.num_batches_tracked', 'model.17.conv.weight', 'model.17.bn.weight', 'model.17.bn.bias', 'model.17.bn.running_mean', 'model.17.bn.running_var', 'model.17.bn.num_batches_tracked', 'model.20.cv1.conv.weight', 'model.20.cv1.bn.weight', 'model.20.cv1.bn.bias', 'model.20.cv1.bn.running_mean', 'model.20.cv1.bn.running_var', 'model.20.cv1.bn.num_batches_tracked', 'model.20.cv2.conv.weight', 'model.20.cv2.bn.weight', 'model.20.cv2.bn.bias', 'model.20.cv2.bn.running_mean', 'model.20.cv2.bn.running_var', 'model.20.cv2.bn.num_batches_tracked', 'model.20.cv3.conv.weight', 'model.20.cv3.bn.weight', 'model.20.cv3.bn.bias', 'model.20.cv3.bn.running_mean', 'model.20.cv3.bn.running_var', 'model.20.cv3.bn.num_batches_tracked', 'model.20.m.0.cv1.conv.weight', 'model.20.m.0.cv1.bn.weight', 'model.20.m.0.cv1.bn.bias', 'model.20.m.0.cv1.bn.running_mean', 'model.20.m.0.cv1.bn.running_var', 'model.20.m.0.cv1.bn.num_batches_tracked', 'model.20.m.0.cv2.conv.weight', 'model.20.m.0.cv2.bn.weight', 'model.20.m.0.cv2.bn.bias', 'model.20.m.0.cv2.bn.running_mean', 'model.20.m.0.cv2.bn.running_var', 'model.20.m.0.cv2.bn.num_batches_tracked', 'model.20.m.1.cv1.conv.weight', 'model.20.m.1.cv1.bn.weight', 'model.20.m.1.cv1.bn.bias', 'model.20.m.1.cv1.bn.running_mean', 'model.20.m.1.cv1.bn.running_var', 'model.20.m.1.cv1.bn.num_batches_tracked', 'model.20.m.1.cv2.conv.weight', 'model.20.m.1.cv2.bn.weight', 'model.20.m.1.cv2.bn.bias', 'model.20.m.1.cv2.bn.running_mean', 'model.20.m.1.cv2.bn.running_var', 'model.20.m.1.cv2.bn.num_batches_tracked', 'model.20.m.2.cv1.conv.weight', 'model.20.m.2.cv1.bn.weight', 'model.20.m.2.cv1.bn.bias', 'model.20.m.2.cv1.bn.running_mean', 'model.20.m.2.cv1.bn.running_var', 'model.20.m.2.cv1.bn.num_batches_tracked', 'model.20.m.2.cv2.conv.weight', 'model.20.m.2.cv2.bn.weight', 'model.20.m.2.cv2.bn.bias', 'model.20.m.2.cv2.bn.running_mean', 'model.20.m.2.cv2.bn.running_var', 'model.20.m.2.cv2.bn.num_batches_tracked', 'model.21.conv.weight', 'model.21.bn.weight', 'model.21.bn.bias', 'model.21.bn.running_mean', 'model.21.bn.running_var', 'model.21.bn.num_batches_tracked', 'model.23.cv1.conv.weight', 'model.23.cv1.bn.weight', 'model.23.cv1.bn.bias', 'model.23.cv1.bn.running_mean', 'model.23.cv1.bn.running_var', 'model.23.cv1.bn.num_batches_tracked', 'model.23.cv2.conv.weight', 'model.23.cv2.bn.weight', 'model.23.cv2.bn.bias', 'model.23.cv2.bn.running_mean', 'model.23.cv2.bn.running_var', 'model.23.cv2.bn.num_batches_tracked', 'model.23.cv3.conv.weight', 'model.23.cv3.bn.weight', 'model.23.cv3.bn.bias', 'model.23.cv3.bn.running_mean', 'model.23.cv3.bn.running_var', 'model.23.cv3.bn.num_batches_tracked', 'model.23.m.0.cv1.conv.weight', 'model.23.m.0.cv1.bn.weight', 'model.23.m.0.cv1.bn.bias', 'model.23.m.0.cv1.bn.running_mean', 'model.23.m.0.cv1.bn.running_var', 'model.23.m.0.cv1.bn.num_batches_tracked', 'model.23.m.0.cv2.conv.weight', 'model.23.m.0.cv2.bn.weight', 'model.23.m.0.cv2.bn.bias', 'model.23.m.0.cv2.bn.running_mean', 'model.23.m.0.cv2.bn.running_var', 'model.23.m.0.cv2.bn.num_batches_tracked', 'model.23.m.1.cv1.conv.weight', 'model.23.m.1.cv1.bn.weight', 'model.23.m.1.cv1.bn.bias', 'model.23.m.1.cv1.bn.running_mean', 'model.23.m.1.cv1.bn.running_var', 'model.23.m.1.cv1.bn.num_batches_tracked', 'model.23.m.1.cv2.conv.weight', 'model.23.m.1.cv2.bn.weight', 'model.23.m.1.cv2.bn.bias', 'model.23.m.1.cv2.bn.running_mean', 'model.23.m.1.cv2.bn.running_var', 'model.23.m.1.cv2.bn.num_batches_tracked', 'model.23.m.2.cv1.conv.weight', 'model.23.m.2.cv1.bn.weight', 'model.23.m.2.cv1.bn.bias', 'model.23.m.2.cv1.bn.running_mean', 'model.23.m.2.cv1.bn.running_var', 'model.23.m.2.cv1.bn.num_batches_tracked', 'model.23.m.2.cv2.conv.weight', 'model.23.m.2.cv2.bn.weight', 'model.23.m.2.cv2.bn.bias', 'model.23.m.2.cv2.bn.running_mean', 'model.23.m.2.cv2.bn.running_var', 'model.23.m.2.cv2.bn.num_batches_tracked', 'model.24.conv.weight', 'model.24.bn.weight', 'model.24.bn.bias', 'model.24.bn.running_mean', 'model.24.bn.running_var', 'model.24.bn.num_batches_tracked', 'model.26.cv1.conv.weight', 'model.26.cv1.bn.weight', 'model.26.cv1.bn.bias', 'model.26.cv1.bn.running_mean', 'model.26.cv1.bn.running_var', 'model.26.cv1.bn.num_batches_tracked', 'model.26.cv2.conv.weight', 'model.26.cv2.bn.weight', 'model.26.cv2.bn.bias', 'model.26.cv2.bn.running_mean', 'model.26.cv2.bn.running_var', 'model.26.cv2.bn.num_batches_tracked', 'model.26.cv3.conv.weight', 'model.26.cv3.bn.weight', 'model.26.cv3.bn.bias', 'model.26.cv3.bn.running_mean', 'model.26.cv3.bn.running_var', 'model.26.cv3.bn.num_batches_tracked', 'model.26.m.0.cv1.conv.weight', 'model.26.m.0.cv1.bn.weight', 'model.26.m.0.cv1.bn.bias', 'model.26.m.0.cv1.bn.running_mean', 'model.26.m.0.cv1.bn.running_var', 'model.26.m.0.cv1.bn.num_batches_tracked', 'model.26.m.0.cv2.conv.weight', 'model.26.m.0.cv2.bn.weight', 'model.26.m.0.cv2.bn.bias', 'model.26.m.0.cv2.bn.running_mean', 'model.26.m.0.cv2.bn.running_var', 'model.26.m.0.cv2.bn.num_batches_tracked', 'model.26.m.1.cv1.conv.weight', 'model.26.m.1.cv1.bn.weight', 'model.26.m.1.cv1.bn.bias', 'model.26.m.1.cv1.bn.running_mean', 'model.26.m.1.cv1.bn.running_var', 'model.26.m.1.cv1.bn.num_batches_tracked', 'model.26.m.1.cv2.conv.weight', 'model.26.m.1.cv2.bn.weight', 'model.26.m.1.cv2.bn.bias', 'model.26.m.1.cv2.bn.running_mean', 'model.26.m.1.cv2.bn.running_var', 'model.26.m.1.cv2.bn.num_batches_tracked', 'model.26.m.2.cv1.conv.weight', 'model.26.m.2.cv1.bn.weight', 'model.26.m.2.cv1.bn.bias', 'model.26.m.2.cv1.bn.running_mean', 'model.26.m.2.cv1.bn.running_var', 'model.26.m.2.cv1.bn.num_batches_tracked', 'model.26.m.2.cv2.conv.weight', 'model.26.m.2.cv2.bn.weight', 'model.26.m.2.cv2.bn.bias', 'model.26.m.2.cv2.bn.running_mean', 'model.26.m.2.cv2.bn.running_var', 'model.26.m.2.cv2.bn.num_batches_tracked', 'model.27.anchors', 'model.27.anchor_grid', 'model.27.m.0.weight', 'model.27.m.0.bias', 'model.27.m.1.weight', 'model.27.m.1.bias', 'model.27.m.2.weight', 'model.27.m.2.bias'])\n",
      "model.0.layer.0.weight torch.Size([64, 3, 7, 7])\n",
      "model.0.layer.1.weight torch.Size([64])\n",
      "model.0.layer.1.bias torch.Size([64])\n",
      "model.0.layer.1.running_mean torch.Size([64])\n",
      "model.0.layer.1.running_var torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "icafusion_model_state_dict = torch.load(\"ICAFusion/runs/train/icafusion_debug_small/weights/best_model_state_dict_only.pth\", map_location=torch.device('cpu'), weights_only=True)\n",
    "# per KAROLINA\n",
    "#/mnt/proj3/eu-25-19/davide_secco/ADL-Project/ICAFusion/icafusion_state_dict_from_Model.pth\n",
    "\n",
    "print(\"Keys in icafusion_model_state_dict:\", icafusion_model_state_dict.keys())\n",
    "\n",
    "for k in list(icafusion_model_state_dict)[:5]:\n",
    "    print(k, icafusion_model_state_dict[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b12ac",
   "metadata": {},
   "source": [
    "Ok coerente, come abbiamo detto qui abbiamo salvato direttamente il model_state_dict\n",
    "\n",
    "//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6041c5",
   "metadata": {},
   "source": [
    "Script per analizzare i diversi \"blocchi\" ottenuti accorpando per nome in base alla profondita' scelta in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c843c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def analyze_state_dict_blocks(state_dict, depth=2, topk=5):\n",
    "    \"\"\"\n",
    "    Analizza prefissi (blocchi) in uno state_dict (PyTorch) e stampa info su raggruppamento e quantità chiavi per blocco.\n",
    "    \n",
    "    Args:\n",
    "        state_dict: dict estratto da .pth/.pt\n",
    "        depth: quanti livelli considerare come nome \"blocco\" (es. 2 -> 'module.backbone_1', 3 -> 'model.0.layer')\n",
    "        topk: quanti layer di esempio stampare per ogni blocco\n",
    "    \"\"\"\n",
    "    block_dict = defaultdict(list)\n",
    "    for k in state_dict.keys():\n",
    "        block_prefix = \".\".join(k.split(\".\")[:depth])\n",
    "        block_dict[block_prefix].append(k)\n",
    "\n",
    "    total_layers = 0\n",
    "    print(f\"Totale chiavi: {len(state_dict)}\")\n",
    "    print(\"=\"*32)\n",
    "    for block_name, keys in block_dict.items():\n",
    "        print(f\"Blocco '{block_name}': {len(keys)} layer\")\n",
    "        total_layers += len(keys)\n",
    "        for k in keys[:topk]:\n",
    "            print(\" -\", k, state_dict[k].shape if hasattr(state_dict[k], 'shape') else type(state_dict[k]))\n",
    "        if len(keys) > topk:\n",
    "            print(f\" ... ({len(keys)-topk} altri)\")\n",
    "        print(\"-\"*20)\n",
    "    print(f\"TOTALE layer contati: {total_layers}\")\n",
    "\n",
    "# ESEMPIO USO:\n",
    "# analyze_state_dict_blocks(decur_model_state_dict, depth=2)\n",
    "# analyze_state_dict_blocks(icafusion_model_state_dict, depth=2)\n",
    "# Puoi regolare depth=2 o 3 in base a come vuoi raggruppare i blocchi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7a723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale chiavi: 665\n",
      "================================\n",
      "Blocco 'module.backbone_1': 318 layer\n",
      " - module.backbone_1.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.backbone_1.bn1.weight torch.Size([64])\n",
      " - module.backbone_1.bn1.bias torch.Size([64])\n",
      " - module.backbone_1.bn1.running_mean torch.Size([64])\n",
      " - module.backbone_1.bn1.running_var torch.Size([64])\n",
      " ... (313 altri)\n",
      "--------------------\n",
      "Blocco 'module.backbone_2': 318 layer\n",
      " - module.backbone_2.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.backbone_2.bn1.weight torch.Size([64])\n",
      " - module.backbone_2.bn1.bias torch.Size([64])\n",
      " - module.backbone_2.bn1.running_mean torch.Size([64])\n",
      " - module.backbone_2.bn1.running_var torch.Size([64])\n",
      " ... (313 altri)\n",
      "--------------------\n",
      "Blocco 'module.projector1': 13 layer\n",
      " - module.projector1.0.weight torch.Size([8192, 2048])\n",
      " - module.projector1.1.weight torch.Size([8192])\n",
      " - module.projector1.1.bias torch.Size([8192])\n",
      " - module.projector1.1.running_mean torch.Size([8192])\n",
      " - module.projector1.1.running_var torch.Size([8192])\n",
      " ... (8 altri)\n",
      "--------------------\n",
      "Blocco 'module.projector2': 13 layer\n",
      " - module.projector2.0.weight torch.Size([8192, 2048])\n",
      " - module.projector2.1.weight torch.Size([8192])\n",
      " - module.projector2.1.bias torch.Size([8192])\n",
      " - module.projector2.1.running_mean torch.Size([8192])\n",
      " - module.projector2.1.running_var torch.Size([8192])\n",
      " ... (8 altri)\n",
      "--------------------\n",
      "Blocco 'module.bn': 3 layer\n",
      " - module.bn.running_mean torch.Size([8192])\n",
      " - module.bn.running_var torch.Size([8192])\n",
      " - module.bn.num_batches_tracked torch.Size([])\n",
      "--------------------\n",
      "TOTALE layer contati: 665\n"
     ]
    }
   ],
   "source": [
    "# DECUR \n",
    "analyze_state_dict_blocks(decur_model_state_dict, depth=2)\n",
    "\n",
    "\n",
    "# Attenzione la backbone 1 e' per l'immagine visibile e la 2 per l'infrarosso credo (da verificare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc81c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale chiavi: 974\n",
      "================================\n",
      "Blocco 'module.queue': 1 layer\n",
      " - module.queue torch.Size([128, 65536])\n",
      "--------------------\n",
      "Blocco 'module.queue_ptr': 1 layer\n",
      " - module.queue_ptr torch.Size([1])\n",
      "--------------------\n",
      "Blocco 'module.queue2': 1 layer\n",
      " - module.queue2 torch.Size([128, 65536])\n",
      "--------------------\n",
      "Blocco 'module.queue2_ptr': 1 layer\n",
      " - module.queue2_ptr torch.Size([1])\n",
      "--------------------\n",
      "Blocco 'module.encoder_q': 326 layer\n",
      " - module.encoder_q.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.encoder_q.0.bn1.weight torch.Size([64])\n",
      " - module.encoder_q.0.bn1.bias torch.Size([64])\n",
      " - module.encoder_q.0.bn1.running_mean torch.Size([64])\n",
      " - module.encoder_q.0.bn1.running_var torch.Size([64])\n",
      " ... (321 altri)\n",
      "--------------------\n",
      "Blocco 'module.encoder_k': 326 layer\n",
      " - module.encoder_k.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.encoder_k.0.bn1.weight torch.Size([64])\n",
      " - module.encoder_k.0.bn1.bias torch.Size([64])\n",
      " - module.encoder_k.0.bn1.running_mean torch.Size([64])\n",
      " - module.encoder_k.0.bn1.running_var torch.Size([64])\n",
      " ... (321 altri)\n",
      "--------------------\n",
      "Blocco 'module.backbone': 318 layer\n",
      " - module.backbone.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.backbone.bn1.weight torch.Size([64])\n",
      " - module.backbone.bn1.bias torch.Size([64])\n",
      " - module.backbone.bn1.running_mean torch.Size([64])\n",
      " - module.backbone.bn1.running_var torch.Size([64])\n",
      " ... (313 altri)\n",
      "--------------------\n",
      "TOTALE layer contati: 974\n"
     ]
    }
   ],
   "source": [
    "# DENSECL\n",
    "analyze_state_dict_blocks(densecl_model_state_dict, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "046ac6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale chiavi: 1951\n",
      "================================\n",
      "Blocco 'module.mod1.queue': 1 layer\n",
      " - module.mod1.queue torch.Size([128, 65536])\n",
      "--------------------\n",
      "Blocco 'module.mod1.queue_ptr': 1 layer\n",
      " - module.mod1.queue_ptr torch.Size([1])\n",
      "--------------------\n",
      "Blocco 'module.mod1.queue2': 1 layer\n",
      " - module.mod1.queue2 torch.Size([128, 65536])\n",
      "--------------------\n",
      "Blocco 'module.mod1.queue2_ptr': 1 layer\n",
      " - module.mod1.queue2_ptr torch.Size([1])\n",
      "--------------------\n",
      "Blocco 'module.mod1.encoder_q': 326 layer\n",
      " - module.mod1.encoder_q.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.mod1.encoder_q.0.bn1.weight torch.Size([64])\n",
      " - module.mod1.encoder_q.0.bn1.bias torch.Size([64])\n",
      " - module.mod1.encoder_q.0.bn1.running_mean torch.Size([64])\n",
      " - module.mod1.encoder_q.0.bn1.running_var torch.Size([64])\n",
      " ... (321 altri)\n",
      "--------------------\n",
      "Blocco 'module.mod1.encoder_k': 326 layer\n",
      " - module.mod1.encoder_k.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.mod1.encoder_k.0.bn1.weight torch.Size([64])\n",
      " - module.mod1.encoder_k.0.bn1.bias torch.Size([64])\n",
      " - module.mod1.encoder_k.0.bn1.running_mean torch.Size([64])\n",
      " - module.mod1.encoder_k.0.bn1.running_var torch.Size([64])\n",
      " ... (321 altri)\n",
      "--------------------\n",
      "Blocco 'module.mod1.backbone': 318 layer\n",
      " - module.mod1.backbone.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.mod1.backbone.bn1.weight torch.Size([64])\n",
      " - module.mod1.backbone.bn1.bias torch.Size([64])\n",
      " - module.mod1.backbone.bn1.running_mean torch.Size([64])\n",
      " - module.mod1.backbone.bn1.running_var torch.Size([64])\n",
      " ... (313 altri)\n",
      "--------------------\n",
      "Blocco 'module.mod2.queue': 1 layer\n",
      " - module.mod2.queue torch.Size([128, 65536])\n",
      "--------------------\n",
      "Blocco 'module.mod2.queue_ptr': 1 layer\n",
      " - module.mod2.queue_ptr torch.Size([1])\n",
      "--------------------\n",
      "Blocco 'module.mod2.queue2': 1 layer\n",
      " - module.mod2.queue2 torch.Size([128, 65536])\n",
      "--------------------\n",
      "Blocco 'module.mod2.queue2_ptr': 1 layer\n",
      " - module.mod2.queue2_ptr torch.Size([1])\n",
      "--------------------\n",
      "Blocco 'module.mod2.encoder_q': 326 layer\n",
      " - module.mod2.encoder_q.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.mod2.encoder_q.0.bn1.weight torch.Size([64])\n",
      " - module.mod2.encoder_q.0.bn1.bias torch.Size([64])\n",
      " - module.mod2.encoder_q.0.bn1.running_mean torch.Size([64])\n",
      " - module.mod2.encoder_q.0.bn1.running_var torch.Size([64])\n",
      " ... (321 altri)\n",
      "--------------------\n",
      "Blocco 'module.mod2.encoder_k': 326 layer\n",
      " - module.mod2.encoder_k.0.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.mod2.encoder_k.0.bn1.weight torch.Size([64])\n",
      " - module.mod2.encoder_k.0.bn1.bias torch.Size([64])\n",
      " - module.mod2.encoder_k.0.bn1.running_mean torch.Size([64])\n",
      " - module.mod2.encoder_k.0.bn1.running_var torch.Size([64])\n",
      " ... (321 altri)\n",
      "--------------------\n",
      "Blocco 'module.mod2.backbone': 318 layer\n",
      " - module.mod2.backbone.conv1.weight torch.Size([64, 3, 7, 7])\n",
      " - module.mod2.backbone.bn1.weight torch.Size([64])\n",
      " - module.mod2.backbone.bn1.bias torch.Size([64])\n",
      " - module.mod2.backbone.bn1.running_mean torch.Size([64])\n",
      " - module.mod2.backbone.bn1.running_var torch.Size([64])\n",
      " ... (313 altri)\n",
      "--------------------\n",
      "Blocco 'module.bn.running_mean': 1 layer\n",
      " - module.bn.running_mean torch.Size([128])\n",
      "--------------------\n",
      "Blocco 'module.bn.running_var': 1 layer\n",
      " - module.bn.running_var torch.Size([128])\n",
      "--------------------\n",
      "Blocco 'module.bn.num_batches_tracked': 1 layer\n",
      " - module.bn.num_batches_tracked torch.Size([])\n",
      "--------------------\n",
      "TOTALE layer contati: 1951\n"
     ]
    }
   ],
   "source": [
    "# DENSEDeCUR\n",
    "analyze_state_dict_blocks(densecur_model_state_dict, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0f6f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale chiavi: 1064\n",
      "================================\n",
      "Blocco 'model.0': 6 layer\n",
      " - model.0.layer.0.weight torch.Size([64, 3, 7, 7])\n",
      " - model.0.layer.1.weight torch.Size([64])\n",
      " - model.0.layer.1.bias torch.Size([64])\n",
      " - model.0.layer.1.running_mean torch.Size([64])\n",
      " - model.0.layer.1.running_var torch.Size([64])\n",
      " ... (1 altri)\n",
      "--------------------\n",
      "Blocco 'model.1': 60 layer\n",
      " - model.1.layer.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      " - model.1.layer.0.bn1.weight torch.Size([64])\n",
      " - model.1.layer.0.bn1.bias torch.Size([64])\n",
      " - model.1.layer.0.bn1.running_mean torch.Size([64])\n",
      " - model.1.layer.0.bn1.running_var torch.Size([64])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.2': 78 layer\n",
      " - model.2.layer.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      " - model.2.layer.0.bn1.weight torch.Size([128])\n",
      " - model.2.layer.0.bn1.bias torch.Size([128])\n",
      " - model.2.layer.0.bn1.running_mean torch.Size([128])\n",
      " - model.2.layer.0.bn1.running_var torch.Size([128])\n",
      " ... (73 altri)\n",
      "--------------------\n",
      "Blocco 'model.3': 114 layer\n",
      " - model.3.layer.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      " - model.3.layer.0.bn1.weight torch.Size([256])\n",
      " - model.3.layer.0.bn1.bias torch.Size([256])\n",
      " - model.3.layer.0.bn1.running_mean torch.Size([256])\n",
      " - model.3.layer.0.bn1.running_var torch.Size([256])\n",
      " ... (109 altri)\n",
      "--------------------\n",
      "Blocco 'model.4': 60 layer\n",
      " - model.4.layer.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      " - model.4.layer.0.bn1.weight torch.Size([512])\n",
      " - model.4.layer.0.bn1.bias torch.Size([512])\n",
      " - model.4.layer.0.bn1.running_mean torch.Size([512])\n",
      " - model.4.layer.0.bn1.running_var torch.Size([512])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.5': 6 layer\n",
      " - model.5.layer.0.weight torch.Size([64, 3, 7, 7])\n",
      " - model.5.layer.1.weight torch.Size([64])\n",
      " - model.5.layer.1.bias torch.Size([64])\n",
      " - model.5.layer.1.running_mean torch.Size([64])\n",
      " - model.5.layer.1.running_var torch.Size([64])\n",
      " ... (1 altri)\n",
      "--------------------\n",
      "Blocco 'model.6': 60 layer\n",
      " - model.6.layer.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      " - model.6.layer.0.bn1.weight torch.Size([64])\n",
      " - model.6.layer.0.bn1.bias torch.Size([64])\n",
      " - model.6.layer.0.bn1.running_mean torch.Size([64])\n",
      " - model.6.layer.0.bn1.running_var torch.Size([64])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.7': 78 layer\n",
      " - model.7.layer.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      " - model.7.layer.0.bn1.weight torch.Size([128])\n",
      " - model.7.layer.0.bn1.bias torch.Size([128])\n",
      " - model.7.layer.0.bn1.running_mean torch.Size([128])\n",
      " - model.7.layer.0.bn1.running_var torch.Size([128])\n",
      " ... (73 altri)\n",
      "--------------------\n",
      "Blocco 'model.8': 114 layer\n",
      " - model.8.layer.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      " - model.8.layer.0.bn1.weight torch.Size([256])\n",
      " - model.8.layer.0.bn1.bias torch.Size([256])\n",
      " - model.8.layer.0.bn1.running_mean torch.Size([256])\n",
      " - model.8.layer.0.bn1.running_var torch.Size([256])\n",
      " ... (109 altri)\n",
      "--------------------\n",
      "Blocco 'model.9': 60 layer\n",
      " - model.9.layer.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      " - model.9.layer.0.bn1.weight torch.Size([512])\n",
      " - model.9.layer.0.bn1.bias torch.Size([512])\n",
      " - model.9.layer.0.bn1.running_mean torch.Size([512])\n",
      " - model.9.layer.0.bn1.running_var torch.Size([512])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.10': 60 layer\n",
      " - model.10.pos_emb_vis torch.Size([1, 400, 512])\n",
      " - model.10.pos_emb_ir torch.Size([1, 400, 512])\n",
      " - model.10.vis_coefficient.w1 torch.Size([1])\n",
      " - model.10.vis_coefficient.w2 torch.Size([1])\n",
      " - model.10.ir_coefficient.w1 torch.Size([1])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.11': 60 layer\n",
      " - model.11.pos_emb_vis torch.Size([1, 256, 1024])\n",
      " - model.11.pos_emb_ir torch.Size([1, 256, 1024])\n",
      " - model.11.vis_coefficient.w1 torch.Size([1])\n",
      " - model.11.vis_coefficient.w2 torch.Size([1])\n",
      " - model.11.ir_coefficient.w1 torch.Size([1])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.12': 60 layer\n",
      " - model.12.pos_emb_vis torch.Size([1, 100, 2048])\n",
      " - model.12.pos_emb_ir torch.Size([1, 100, 2048])\n",
      " - model.12.vis_coefficient.w1 torch.Size([1])\n",
      " - model.12.vis_coefficient.w2 torch.Size([1])\n",
      " - model.12.ir_coefficient.w1 torch.Size([1])\n",
      " ... (55 altri)\n",
      "--------------------\n",
      "Blocco 'model.13': 6 layer\n",
      " - model.13.conv.weight torch.Size([1024, 2048, 1, 1])\n",
      " - model.13.bn.weight torch.Size([1024])\n",
      " - model.13.bn.bias torch.Size([1024])\n",
      " - model.13.bn.running_mean torch.Size([1024])\n",
      " - model.13.bn.running_var torch.Size([1024])\n",
      " ... (1 altri)\n",
      "--------------------\n",
      "Blocco 'model.16': 54 layer\n",
      " - model.16.cv1.conv.weight torch.Size([512, 2048, 1, 1])\n",
      " - model.16.cv1.bn.weight torch.Size([512])\n",
      " - model.16.cv1.bn.bias torch.Size([512])\n",
      " - model.16.cv1.bn.running_mean torch.Size([512])\n",
      " - model.16.cv1.bn.running_var torch.Size([512])\n",
      " ... (49 altri)\n",
      "--------------------\n",
      "Blocco 'model.17': 6 layer\n",
      " - model.17.conv.weight torch.Size([512, 1024, 1, 1])\n",
      " - model.17.bn.weight torch.Size([512])\n",
      " - model.17.bn.bias torch.Size([512])\n",
      " - model.17.bn.running_mean torch.Size([512])\n",
      " - model.17.bn.running_var torch.Size([512])\n",
      " ... (1 altri)\n",
      "--------------------\n",
      "Blocco 'model.20': 54 layer\n",
      " - model.20.cv1.conv.weight torch.Size([256, 1024, 1, 1])\n",
      " - model.20.cv1.bn.weight torch.Size([256])\n",
      " - model.20.cv1.bn.bias torch.Size([256])\n",
      " - model.20.cv1.bn.running_mean torch.Size([256])\n",
      " - model.20.cv1.bn.running_var torch.Size([256])\n",
      " ... (49 altri)\n",
      "--------------------\n",
      "Blocco 'model.21': 6 layer\n",
      " - model.21.conv.weight torch.Size([512, 512, 3, 3])\n",
      " - model.21.bn.weight torch.Size([512])\n",
      " - model.21.bn.bias torch.Size([512])\n",
      " - model.21.bn.running_mean torch.Size([512])\n",
      " - model.21.bn.running_var torch.Size([512])\n",
      " ... (1 altri)\n",
      "--------------------\n",
      "Blocco 'model.23': 54 layer\n",
      " - model.23.cv1.conv.weight torch.Size([512, 1024, 1, 1])\n",
      " - model.23.cv1.bn.weight torch.Size([512])\n",
      " - model.23.cv1.bn.bias torch.Size([512])\n",
      " - model.23.cv1.bn.running_mean torch.Size([512])\n",
      " - model.23.cv1.bn.running_var torch.Size([512])\n",
      " ... (49 altri)\n",
      "--------------------\n",
      "Blocco 'model.24': 6 layer\n",
      " - model.24.conv.weight torch.Size([1024, 1024, 3, 3])\n",
      " - model.24.bn.weight torch.Size([1024])\n",
      " - model.24.bn.bias torch.Size([1024])\n",
      " - model.24.bn.running_mean torch.Size([1024])\n",
      " - model.24.bn.running_var torch.Size([1024])\n",
      " ... (1 altri)\n",
      "--------------------\n",
      "Blocco 'model.26': 54 layer\n",
      " - model.26.cv1.conv.weight torch.Size([1024, 2048, 1, 1])\n",
      " - model.26.cv1.bn.weight torch.Size([1024])\n",
      " - model.26.cv1.bn.bias torch.Size([1024])\n",
      " - model.26.cv1.bn.running_mean torch.Size([1024])\n",
      " - model.26.cv1.bn.running_var torch.Size([1024])\n",
      " ... (49 altri)\n",
      "--------------------\n",
      "Blocco 'model.27': 8 layer\n",
      " - model.27.anchors torch.Size([3, 3, 2])\n",
      " - model.27.anchor_grid torch.Size([3, 1, 3, 1, 1, 2])\n",
      " - model.27.m.0.weight torch.Size([18, 512, 1, 1])\n",
      " - model.27.m.0.bias torch.Size([18])\n",
      " - model.27.m.1.weight torch.Size([18, 1024, 1, 1])\n",
      " ... (3 altri)\n",
      "--------------------\n",
      "TOTALE layer contati: 1064\n"
     ]
    }
   ],
   "source": [
    "# ICAFusion\n",
    "analyze_state_dict_blocks(icafusion_model_state_dict, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd4735",
   "metadata": {},
   "source": [
    "### DeCUR to ICA\n",
    "DeCUR:\n",
    "\n",
    "module.backbone_1.* → backbone per modalità 1 (visible)\n",
    "\n",
    "module.backbone_2.* → backbone per modalità 2 (infrared)\n",
    "\n",
    "ICAFusion:\n",
    "\n",
    "\n",
    "model.0.*, model.1.*, ..., model.4.* → Backbone 1  --  PER VISIBLE VERIFICATO  \n",
    "(inizio a 64, 3, 7, 7 → tipica conv1)\n",
    "\n",
    "model.5.*, model.6.*, ..., model.9.* → Backbone 2  --  PER INFRARED VERIFICATO  \n",
    "(inizio a 64, 3, 7, 7 → tipica conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de3a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione di comodo per stampare i primi n layer di uno state_dict\n",
    "\n",
    "def print_first_layers(state_dict, n=40, title=\"STATE_DICT\"):\n",
    "    print(f\"\\n--- {title} (primi {n} layer) ---\")\n",
    "    for i, (k, v) in enumerate(state_dict.items()):\n",
    "        if i >= n:\n",
    "            break\n",
    "        shape_info = v.shape if hasattr(v, 'shape') else type(v)\n",
    "        print(f\"[{i:03d}] {k:50} {shape_info}\")\n",
    "\n",
    "# Usa così:\n",
    "# print_first_layers(decur_state_dict, n=40, title=\"DeCUR CHECKPOINT\")\n",
    "# print_first_layers(icafusion_state_dict, n=40, title=\"ICAFUSION CHECKPOINT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a458c45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DeCUR MODEL STATE_DICT (primi 40 layer) ---\n",
      "[000] module.backbone_1.conv1.weight                     torch.Size([64, 3, 7, 7])\n",
      "[001] module.backbone_1.bn1.weight                       torch.Size([64])\n",
      "[002] module.backbone_1.bn1.bias                         torch.Size([64])\n",
      "[003] module.backbone_1.bn1.running_mean                 torch.Size([64])\n",
      "[004] module.backbone_1.bn1.running_var                  torch.Size([64])\n",
      "[005] module.backbone_1.bn1.num_batches_tracked          torch.Size([])\n",
      "[006] module.backbone_1.layer1.0.conv1.weight            torch.Size([64, 64, 1, 1])\n",
      "[007] module.backbone_1.layer1.0.bn1.weight              torch.Size([64])\n",
      "[008] module.backbone_1.layer1.0.bn1.bias                torch.Size([64])\n",
      "[009] module.backbone_1.layer1.0.bn1.running_mean        torch.Size([64])\n",
      "[010] module.backbone_1.layer1.0.bn1.running_var         torch.Size([64])\n",
      "[011] module.backbone_1.layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "[012] module.backbone_1.layer1.0.conv2.weight            torch.Size([64, 64, 3, 3])\n",
      "[013] module.backbone_1.layer1.0.bn2.weight              torch.Size([64])\n",
      "[014] module.backbone_1.layer1.0.bn2.bias                torch.Size([64])\n",
      "[015] module.backbone_1.layer1.0.bn2.running_mean        torch.Size([64])\n",
      "[016] module.backbone_1.layer1.0.bn2.running_var         torch.Size([64])\n",
      "[017] module.backbone_1.layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "[018] module.backbone_1.layer1.0.conv3.weight            torch.Size([256, 64, 1, 1])\n",
      "[019] module.backbone_1.layer1.0.bn3.weight              torch.Size([256])\n",
      "[020] module.backbone_1.layer1.0.bn3.bias                torch.Size([256])\n",
      "[021] module.backbone_1.layer1.0.bn3.running_mean        torch.Size([256])\n",
      "[022] module.backbone_1.layer1.0.bn3.running_var         torch.Size([256])\n",
      "[023] module.backbone_1.layer1.0.bn3.num_batches_tracked torch.Size([])\n",
      "[024] module.backbone_1.layer1.0.downsample.0.weight     torch.Size([256, 64, 1, 1])\n",
      "[025] module.backbone_1.layer1.0.downsample.1.weight     torch.Size([256])\n",
      "[026] module.backbone_1.layer1.0.downsample.1.bias       torch.Size([256])\n",
      "[027] module.backbone_1.layer1.0.downsample.1.running_mean torch.Size([256])\n",
      "[028] module.backbone_1.layer1.0.downsample.1.running_var torch.Size([256])\n",
      "[029] module.backbone_1.layer1.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "[030] module.backbone_1.layer1.1.conv1.weight            torch.Size([64, 256, 1, 1])\n",
      "[031] module.backbone_1.layer1.1.bn1.weight              torch.Size([64])\n",
      "[032] module.backbone_1.layer1.1.bn1.bias                torch.Size([64])\n",
      "[033] module.backbone_1.layer1.1.bn1.running_mean        torch.Size([64])\n",
      "[034] module.backbone_1.layer1.1.bn1.running_var         torch.Size([64])\n",
      "[035] module.backbone_1.layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "[036] module.backbone_1.layer1.1.conv2.weight            torch.Size([64, 64, 3, 3])\n",
      "[037] module.backbone_1.layer1.1.bn2.weight              torch.Size([64])\n",
      "[038] module.backbone_1.layer1.1.bn2.bias                torch.Size([64])\n",
      "[039] module.backbone_1.layer1.1.bn2.running_mean        torch.Size([64])\n",
      "\n",
      "--- ICAFUSION MODEL STATE_DICT (primi 40 layer) ---\n",
      "[000] model.0.layer.0.weight                             torch.Size([64, 3, 7, 7])\n",
      "[001] model.0.layer.1.weight                             torch.Size([64])\n",
      "[002] model.0.layer.1.bias                               torch.Size([64])\n",
      "[003] model.0.layer.1.running_mean                       torch.Size([64])\n",
      "[004] model.0.layer.1.running_var                        torch.Size([64])\n",
      "[005] model.0.layer.1.num_batches_tracked                torch.Size([])\n",
      "[006] model.1.layer.0.conv1.weight                       torch.Size([64, 64, 1, 1])\n",
      "[007] model.1.layer.0.bn1.weight                         torch.Size([64])\n",
      "[008] model.1.layer.0.bn1.bias                           torch.Size([64])\n",
      "[009] model.1.layer.0.bn1.running_mean                   torch.Size([64])\n",
      "[010] model.1.layer.0.bn1.running_var                    torch.Size([64])\n",
      "[011] model.1.layer.0.bn1.num_batches_tracked            torch.Size([])\n",
      "[012] model.1.layer.0.conv2.weight                       torch.Size([64, 64, 3, 3])\n",
      "[013] model.1.layer.0.bn2.weight                         torch.Size([64])\n",
      "[014] model.1.layer.0.bn2.bias                           torch.Size([64])\n",
      "[015] model.1.layer.0.bn2.running_mean                   torch.Size([64])\n",
      "[016] model.1.layer.0.bn2.running_var                    torch.Size([64])\n",
      "[017] model.1.layer.0.bn2.num_batches_tracked            torch.Size([])\n",
      "[018] model.1.layer.0.conv3.weight                       torch.Size([256, 64, 1, 1])\n",
      "[019] model.1.layer.0.bn3.weight                         torch.Size([256])\n",
      "[020] model.1.layer.0.bn3.bias                           torch.Size([256])\n",
      "[021] model.1.layer.0.bn3.running_mean                   torch.Size([256])\n",
      "[022] model.1.layer.0.bn3.running_var                    torch.Size([256])\n",
      "[023] model.1.layer.0.bn3.num_batches_tracked            torch.Size([])\n",
      "[024] model.1.layer.0.shortcut.0.weight                  torch.Size([256, 64, 1, 1])\n",
      "[025] model.1.layer.0.shortcut.1.weight                  torch.Size([256])\n",
      "[026] model.1.layer.0.shortcut.1.bias                    torch.Size([256])\n",
      "[027] model.1.layer.0.shortcut.1.running_mean            torch.Size([256])\n",
      "[028] model.1.layer.0.shortcut.1.running_var             torch.Size([256])\n",
      "[029] model.1.layer.0.shortcut.1.num_batches_tracked     torch.Size([])\n",
      "[030] model.1.layer.1.conv1.weight                       torch.Size([64, 256, 1, 1])\n",
      "[031] model.1.layer.1.bn1.weight                         torch.Size([64])\n",
      "[032] model.1.layer.1.bn1.bias                           torch.Size([64])\n",
      "[033] model.1.layer.1.bn1.running_mean                   torch.Size([64])\n",
      "[034] model.1.layer.1.bn1.running_var                    torch.Size([64])\n",
      "[035] model.1.layer.1.bn1.num_batches_tracked            torch.Size([])\n",
      "[036] model.1.layer.1.conv2.weight                       torch.Size([64, 64, 3, 3])\n",
      "[037] model.1.layer.1.bn2.weight                         torch.Size([64])\n",
      "[038] model.1.layer.1.bn2.bias                           torch.Size([64])\n",
      "[039] model.1.layer.1.bn2.running_mean                   torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Stampiamo i primi `n` layer di entrambi gli state_dict per confronto\n",
    "\n",
    "print_first_layers(decur_model_state_dict, n=40, title=\"DeCUR MODEL STATE_DICT\")\n",
    "print_first_layers(icafusion_model_state_dict, n=40, title=\"ICAFUSION MODEL STATE_DICT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c0109",
   "metadata": {},
   "source": [
    "```\n",
    "Funzione che effettua il key mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8390d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_decur_to_ica_semantic(icafusion_state_dict, decur_state_dict, backbone_id=1):\n",
    "    \"\"\"\n",
    "    Mapping da DeCUR backbone_{id} verso la backbone ICAfusion corrispondente,\n",
    "    correggendo differenze di denomimazione (es: downsample vs shortcut).\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Il risultato finale (new_state_dict) conterrà tutto: pesi backbone aggiornati e tutto il resto come prima.\n",
    "    new_state_dict = icafusion_state_dict.copy()\n",
    "    # Su quale backbone di DeCUR lavoriamo (1 o 2) \n",
    "    decur_prefix = f\"module.backbone_{backbone_id}.\"\n",
    "\n",
    "    # Offset backbone 1 = model.0-4, backbone 2 = model.5-9 come mostrato sopra\n",
    "    ica_offset = 0 if backbone_id == 1 else 5\n",
    "    matched, skipped = [], []\n",
    "\n",
    "    for k_decur, v_decur in decur_state_dict.items():\n",
    "        if not k_decur.startswith(decur_prefix):  # skippa chiavi non della backbone corretta\n",
    "            continue\n",
    "        # esempio: da module.backbone_1.conv1.weight  a conv1.weight \n",
    "        # da module.backbone_1.layer1.0.conv1.weight a layer1.0.conv1.weight\n",
    "        short = k_decur.replace(decur_prefix, '')\n",
    "\n",
    "        # Conv1/Bn1 (iniziali)   i primi 5 layer in DECUR\n",
    "        if short.startswith('conv1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.0\" + short[len('conv1'):]\n",
    "        elif short.startswith('bn1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.1\" + short[len('bn1'):]\n",
    "        # Blocchi residui layer1-4 (es: layer1.0.conv1.weight)  i restanti layer in DECUR\n",
    "        elif short.startswith('layer'):\n",
    "            # Estraggo blocco/resid interno:\n",
    "            # esempio: layer1.0.conv2.weight\n",
    "            m = re.match(r\"layer(\\d)\\.(\\d+)\\.(.*)\", short)\n",
    "            if not m:\n",
    "                skipped.append((k_decur, \"no regex match\"))\n",
    "                continue\n",
    "            block_num, block_idx, sublayer = m.groups()\n",
    "            k_ica = f\"model.{ica_offset + int(block_num)}.layer.{block_idx}.{sublayer}\"\n",
    "            \n",
    "            # Correzione unica differenza di nomenclatura layer. \n",
    "            # DeCUR usa 'downsample' mentre ICAfusion usa 'shortcut'\n",
    "            k_ica = k_ica.replace('downsample', 'shortcut')\n",
    "        else:\n",
    "            skipped.append((k_decur, \"no mapping rule\"))\n",
    "            continue\n",
    "\n",
    "        # Check presenza e shape!\n",
    "        if k_ica in icafusion_state_dict and icafusion_state_dict[k_ica].shape == v_decur.shape:\n",
    "            new_state_dict[k_ica] = v_decur\n",
    "            matched.append((k_decur, k_ica))\n",
    "        else:\n",
    "            skipped.append((k_decur, k_ica))\n",
    "\n",
    "    print(f\"[Backbone {backbone_id}] Matchati: {len(matched)}. Saltati: {len(skipped)}\")\n",
    "    if len(matched) < 10:\n",
    "        print(\"Esempi matching:\", matched[:10])\n",
    "    if len(skipped) > 0:\n",
    "        print(\"Esempi saltati:\", skipped[:10])\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc1919",
   "metadata": {},
   "source": [
    "```\n",
    "Convertiamo DeCUR backbone1 to ICAFusion (318 layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0743e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Backbone 1] Matchati: 318. Saltati: 0\n"
     ]
    }
   ],
   "source": [
    "new_icafusion_model_state_dict = map_decur_to_ica_semantic(icafusion_model_state_dict, decur_model_state_dict, backbone_id=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b9d2c",
   "metadata": {},
   "source": [
    "Ora stampiamo per verifica i primi 5 layer del nuovo ica_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e464dfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ICAFUSION MODEL STATE_DICT (primi 10 layer) ---\n",
      "[000] model.0.layer.0.weight                             torch.Size([64, 3, 7, 7])\n",
      "[001] model.0.layer.1.weight                             torch.Size([64])\n",
      "[002] model.0.layer.1.bias                               torch.Size([64])\n",
      "[003] model.0.layer.1.running_mean                       torch.Size([64])\n",
      "[004] model.0.layer.1.running_var                        torch.Size([64])\n",
      "[005] model.0.layer.1.num_batches_tracked                torch.Size([])\n",
      "[006] model.1.layer.0.conv1.weight                       torch.Size([64, 64, 1, 1])\n",
      "[007] model.1.layer.0.bn1.weight                         torch.Size([64])\n",
      "[008] model.1.layer.0.bn1.bias                           torch.Size([64])\n",
      "[009] model.1.layer.0.bn1.running_mean                   torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print_first_layers(new_icafusion_model_state_dict, n=10, title=\"ICAFUSION MODEL STATE_DICT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0d511",
   "metadata": {},
   "source": [
    "```\n",
    "Convertiamo DeCUR backbone2 to ICAFusion (318 layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f329d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Backbone 2] Matchati: 318. Saltati: 0\n"
     ]
    }
   ],
   "source": [
    "# usiamo sempre lo stesso new_icafusion_model_state_dict\n",
    "# sara' la funzione a mappare backbone 2 con la seconda parte dello state_dict di ICA come visto sopra (model.5-9)\n",
    "# Ricordarsi alla seconda run di passare new_icafusion_model_state_dict altrimenti la prima parte fatta viene persa! \n",
    "new_icafusion_model_state_dict = map_decur_to_ica_semantic(new_icafusion_model_state_dict, decur_model_state_dict, backbone_id=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760cc1d",
   "metadata": {},
   "source": [
    "```\n",
    "Check pesi tra stessi layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "896486f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_first_params_comparison(decur_state_dict, ica_state_dict, idx_start=0, idx_end=318):\n",
    "    \"\"\"\n",
    "    Stampa i primi 5 pesi di ogni layer tra decur e ica per indice da idx_start a idx_end (non incluso end).\n",
    "    ATTENZIONE: funziona solo se gli stessi indici sono layer omologhi!\n",
    "    \"\"\"\n",
    "    decur_items = list(decur_state_dict.items())\n",
    "    ica_items = list(ica_state_dict.items())\n",
    "    print(f\"\\n--- CONFRONTO PESI da {idx_start} a {idx_end-1} ---\")\n",
    "    for i in range(idx_start, min(idx_end, len(decur_items), len(ica_items))):\n",
    "        decur_k, decur_v = decur_items[i]\n",
    "        ica_k, ica_v = ica_items[i]\n",
    "        # Controlla sia torch.Tensor\n",
    "        if hasattr(decur_v, 'flatten') and hasattr(ica_v, 'flatten'):\n",
    "            decur_vals = decur_v.flatten()[:5].tolist()\n",
    "            ica_vals   = ica_v.flatten()[:5].tolist()\n",
    "        else:\n",
    "            decur_vals = str(type(decur_v))\n",
    "            ica_vals = str(type(ica_v))\n",
    "        print(f\"[{i:03d}] {decur_k:45} vs {ica_k:45}\")\n",
    "        print(f\"    DeCUR: {decur_vals}\")\n",
    "        print(f\"    ICA:   {ica_vals}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ed3c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CONFRONTO PESI da 0 a 9 ---\n",
      "[000] module.backbone_1.conv1.weight                vs model.0.layer.0.weight                       \n",
      "    DeCUR: [0.013396266847848892, 0.014718021266162395, -0.01529888715595007, -0.022915339097380638, -0.04084962606430054]\n",
      "    ICA:   [0.013396266847848892, 0.014718021266162395, -0.01529888715595007, -0.022915339097380638, -0.04084962606430054]\n",
      "\n",
      "[001] module.backbone_1.bn1.weight                  vs model.0.layer.1.weight                       \n",
      "    DeCUR: [-3.009823799133301, -3.5902647972106934, -0.3451964557170868, 4.228105068206787, 1.2115955352783203]\n",
      "    ICA:   [-3.009823799133301, -3.5902647972106934, -0.3451964557170868, 4.228105068206787, 1.2115955352783203]\n",
      "\n",
      "[002] module.backbone_1.bn1.bias                    vs model.0.layer.1.bias                         \n",
      "    DeCUR: [0.13379108905792236, 0.1611424833536148, -0.4258095324039459, 0.180825337767601, 0.32104358077049255]\n",
      "    ICA:   [0.13379108905792236, 0.1611424833536148, -0.4258095324039459, 0.180825337767601, 0.32104358077049255]\n",
      "\n",
      "[003] module.backbone_1.bn1.running_mean            vs model.0.layer.1.running_mean                 \n",
      "    DeCUR: [0.1192447692155838, 0.09239163994789124, 0.9989098310470581, -0.11215370148420334, -0.057890839874744415]\n",
      "    ICA:   [0.1192447692155838, 0.09239163994789124, 0.9989098310470581, -0.11215370148420334, -0.057890839874744415]\n",
      "\n",
      "[004] module.backbone_1.bn1.running_var             vs model.0.layer.1.running_var                  \n",
      "    DeCUR: [0.8506262898445129, 1.5584503412246704, 1.8294241428375244, 3.9610114097595215, 0.5762119889259338]\n",
      "    ICA:   [0.8506262898445129, 1.5584503412246704, 1.8294241428375244, 3.9610114097595215, 0.5762119889259338]\n",
      "\n",
      "[005] module.backbone_1.bn1.num_batches_tracked     vs model.0.layer.1.num_batches_tracked          \n",
      "    DeCUR: [730]\n",
      "    ICA:   [730]\n",
      "\n",
      "[006] module.backbone_1.layer1.0.conv1.weight       vs model.1.layer.0.conv1.weight                 \n",
      "    DeCUR: [0.0035698863212019205, 0.039817508310079575, -0.02476814202964306, -0.027694353833794594, 0.08883612602949142]\n",
      "    ICA:   [0.0035698863212019205, 0.039817508310079575, -0.02476814202964306, -0.027694353833794594, 0.08883612602949142]\n",
      "\n",
      "[007] module.backbone_1.layer1.0.bn1.weight         vs model.1.layer.0.bn1.weight                   \n",
      "    DeCUR: [-2.5341179370880127, 0.9399570226669312, -0.23100239038467407, -0.627301037311554, 3.7958321571350098]\n",
      "    ICA:   [-2.5341179370880127, 0.9399570226669312, -0.23100239038467407, -0.627301037311554, 3.7958321571350098]\n",
      "\n",
      "[008] module.backbone_1.layer1.0.bn1.bias           vs model.1.layer.0.bn1.bias                     \n",
      "    DeCUR: [4.330828666687012, -1.9062978029251099, -0.30034491419792175, -0.6305217742919922, 2.1954941749572754]\n",
      "    ICA:   [4.330828666687012, -1.9062978029251099, -0.30034491419792175, -0.6305217742919922, 2.1954941749572754]\n",
      "\n",
      "[009] module.backbone_1.layer1.0.bn1.running_mean   vs model.1.layer.0.bn1.running_mean             \n",
      "    DeCUR: [-2.5134100914001465, -1.3570547103881836, 1.4472527503967285, -0.7909970879554749, -0.3423619568347931]\n",
      "    ICA:   [-2.5134100914001465, -1.3570547103881836, 1.4472527503967285, -0.7909970879554749, -0.3423619568347931]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confrontiamo i primi 10 layer (indici 0-9) tra i due state_dict DECUR e NUOVO ICAFUSION\n",
    "print_first_params_comparison(decur_model_state_dict, new_icafusion_model_state_dict, idx_start=0, idx_end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee6727",
   "metadata": {},
   "source": [
    "```\n",
    "FUNZIONANTE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff052e39",
   "metadata": {},
   "source": [
    "### DenseCL to ICA\n",
    "DenseCL:\n",
    "\n",
    "* Da primo pretraining con immagini rgb o chiamate in ICA visible  \n",
    "-> module.encoder_q.* → backbone per modalità 1 (visible)\n",
    "\n",
    "* Da secondo pretraining con immagini thermal o chiamate in ICA infrared  \n",
    "-> module.encoder_q.* → backbone per modalità 1 (infrared)\n",
    "\n",
    "ICAFusion:\n",
    "\n",
    "model.0.*, model.1.*, ..., model.4.* → Backbone 1  --  PER VISIBLE VERIFICATO  \n",
    "(inizio a 64, 3, 7, 7 → tipica conv1)\n",
    "\n",
    "model.5.*, model.6.*, ..., model.9.* → Backbone 2  --  PER INFRARED VERIFICATO  \n",
    "(inizio a 64, 3, 7, 7 → tipica conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b80742",
   "metadata": {},
   "source": [
    "```\n",
    "Per questo script quindi serviranno due densecl_model_state_dict     aggiungere nome rgb e thermal prima di salvarlo per distinguerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd261f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DenseCL MODEL STATE_DICT (primi 40 layer) ---\n",
      "[000] module.queue                                       torch.Size([128, 65536])\n",
      "[001] module.queue_ptr                                   torch.Size([1])\n",
      "[002] module.queue2                                      torch.Size([128, 65536])\n",
      "[003] module.queue2_ptr                                  torch.Size([1])\n",
      "[004] module.encoder_q.0.conv1.weight                    torch.Size([64, 3, 7, 7])\n",
      "[005] module.encoder_q.0.bn1.weight                      torch.Size([64])\n",
      "[006] module.encoder_q.0.bn1.bias                        torch.Size([64])\n",
      "[007] module.encoder_q.0.bn1.running_mean                torch.Size([64])\n",
      "[008] module.encoder_q.0.bn1.running_var                 torch.Size([64])\n",
      "[009] module.encoder_q.0.bn1.num_batches_tracked         torch.Size([])\n",
      "[010] module.encoder_q.0.layer1.0.conv1.weight           torch.Size([64, 64, 1, 1])\n",
      "[011] module.encoder_q.0.layer1.0.bn1.weight             torch.Size([64])\n",
      "[012] module.encoder_q.0.layer1.0.bn1.bias               torch.Size([64])\n",
      "[013] module.encoder_q.0.layer1.0.bn1.running_mean       torch.Size([64])\n",
      "[014] module.encoder_q.0.layer1.0.bn1.running_var        torch.Size([64])\n",
      "[015] module.encoder_q.0.layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "[016] module.encoder_q.0.layer1.0.conv2.weight           torch.Size([64, 64, 3, 3])\n",
      "[017] module.encoder_q.0.layer1.0.bn2.weight             torch.Size([64])\n",
      "[018] module.encoder_q.0.layer1.0.bn2.bias               torch.Size([64])\n",
      "[019] module.encoder_q.0.layer1.0.bn2.running_mean       torch.Size([64])\n",
      "[020] module.encoder_q.0.layer1.0.bn2.running_var        torch.Size([64])\n",
      "[021] module.encoder_q.0.layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "[022] module.encoder_q.0.layer1.0.conv3.weight           torch.Size([256, 64, 1, 1])\n",
      "[023] module.encoder_q.0.layer1.0.bn3.weight             torch.Size([256])\n",
      "[024] module.encoder_q.0.layer1.0.bn3.bias               torch.Size([256])\n",
      "[025] module.encoder_q.0.layer1.0.bn3.running_mean       torch.Size([256])\n",
      "[026] module.encoder_q.0.layer1.0.bn3.running_var        torch.Size([256])\n",
      "[027] module.encoder_q.0.layer1.0.bn3.num_batches_tracked torch.Size([])\n",
      "[028] module.encoder_q.0.layer1.0.downsample.0.weight    torch.Size([256, 64, 1, 1])\n",
      "[029] module.encoder_q.0.layer1.0.downsample.1.weight    torch.Size([256])\n",
      "[030] module.encoder_q.0.layer1.0.downsample.1.bias      torch.Size([256])\n",
      "[031] module.encoder_q.0.layer1.0.downsample.1.running_mean torch.Size([256])\n",
      "[032] module.encoder_q.0.layer1.0.downsample.1.running_var torch.Size([256])\n",
      "[033] module.encoder_q.0.layer1.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "[034] module.encoder_q.0.layer1.1.conv1.weight           torch.Size([64, 256, 1, 1])\n",
      "[035] module.encoder_q.0.layer1.1.bn1.weight             torch.Size([64])\n",
      "[036] module.encoder_q.0.layer1.1.bn1.bias               torch.Size([64])\n",
      "[037] module.encoder_q.0.layer1.1.bn1.running_mean       torch.Size([64])\n",
      "[038] module.encoder_q.0.layer1.1.bn1.running_var        torch.Size([64])\n",
      "[039] module.encoder_q.0.layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "\n",
      "--- ICAFUSION MODEL STATE_DICT (primi 40 layer) ---\n",
      "[000] model.0.layer.0.weight                             torch.Size([64, 3, 7, 7])\n",
      "[001] model.0.layer.1.weight                             torch.Size([64])\n",
      "[002] model.0.layer.1.bias                               torch.Size([64])\n",
      "[003] model.0.layer.1.running_mean                       torch.Size([64])\n",
      "[004] model.0.layer.1.running_var                        torch.Size([64])\n",
      "[005] model.0.layer.1.num_batches_tracked                torch.Size([])\n",
      "[006] model.1.layer.0.conv1.weight                       torch.Size([64, 64, 1, 1])\n",
      "[007] model.1.layer.0.bn1.weight                         torch.Size([64])\n",
      "[008] model.1.layer.0.bn1.bias                           torch.Size([64])\n",
      "[009] model.1.layer.0.bn1.running_mean                   torch.Size([64])\n",
      "[010] model.1.layer.0.bn1.running_var                    torch.Size([64])\n",
      "[011] model.1.layer.0.bn1.num_batches_tracked            torch.Size([])\n",
      "[012] model.1.layer.0.conv2.weight                       torch.Size([64, 64, 3, 3])\n",
      "[013] model.1.layer.0.bn2.weight                         torch.Size([64])\n",
      "[014] model.1.layer.0.bn2.bias                           torch.Size([64])\n",
      "[015] model.1.layer.0.bn2.running_mean                   torch.Size([64])\n",
      "[016] model.1.layer.0.bn2.running_var                    torch.Size([64])\n",
      "[017] model.1.layer.0.bn2.num_batches_tracked            torch.Size([])\n",
      "[018] model.1.layer.0.conv3.weight                       torch.Size([256, 64, 1, 1])\n",
      "[019] model.1.layer.0.bn3.weight                         torch.Size([256])\n",
      "[020] model.1.layer.0.bn3.bias                           torch.Size([256])\n",
      "[021] model.1.layer.0.bn3.running_mean                   torch.Size([256])\n",
      "[022] model.1.layer.0.bn3.running_var                    torch.Size([256])\n",
      "[023] model.1.layer.0.bn3.num_batches_tracked            torch.Size([])\n",
      "[024] model.1.layer.0.shortcut.0.weight                  torch.Size([256, 64, 1, 1])\n",
      "[025] model.1.layer.0.shortcut.1.weight                  torch.Size([256])\n",
      "[026] model.1.layer.0.shortcut.1.bias                    torch.Size([256])\n",
      "[027] model.1.layer.0.shortcut.1.running_mean            torch.Size([256])\n",
      "[028] model.1.layer.0.shortcut.1.running_var             torch.Size([256])\n",
      "[029] model.1.layer.0.shortcut.1.num_batches_tracked     torch.Size([])\n",
      "[030] model.1.layer.1.conv1.weight                       torch.Size([64, 256, 1, 1])\n",
      "[031] model.1.layer.1.bn1.weight                         torch.Size([64])\n",
      "[032] model.1.layer.1.bn1.bias                           torch.Size([64])\n",
      "[033] model.1.layer.1.bn1.running_mean                   torch.Size([64])\n",
      "[034] model.1.layer.1.bn1.running_var                    torch.Size([64])\n",
      "[035] model.1.layer.1.bn1.num_batches_tracked            torch.Size([])\n",
      "[036] model.1.layer.1.conv2.weight                       torch.Size([64, 64, 3, 3])\n",
      "[037] model.1.layer.1.bn2.weight                         torch.Size([64])\n",
      "[038] model.1.layer.1.bn2.bias                           torch.Size([64])\n",
      "[039] model.1.layer.1.bn2.running_mean                   torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print_first_layers(densecl_model_state_dict, n=40, title=\"DenseCL MODEL STATE_DICT\")\n",
    "print_first_layers(icafusion_model_state_dict, n=40, title=\"ICAFUSION MODEL STATE_DICT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e207f0b2",
   "metadata": {},
   "source": [
    "```\n",
    "Funzione che effettua il key mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de97068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_densecl_to_ica(icafusion_state_dict, densecl_state_dict, domain):\n",
    "    \"\"\"\n",
    "    Mappa i pesi di encoder_q di DenseCL per uno specifico dominio\n",
    "    (visible o infrared) nella backbone omologa di ICAfusion.\n",
    "    - domain: 'visible' -> ICA model.0-4 ; 'infrared' -> model.5-9\n",
    "    \"\"\"\n",
    "    import re\n",
    "    new_state_dict = icafusion_state_dict.copy()\n",
    "    prefix = \"module.encoder_q.0.\"\n",
    "    ica_offset = 0 if domain == 'visible' else 5\n",
    "    matched, skipped = [], []\n",
    "\n",
    "    for k_densecl, v_densecl in densecl_state_dict.items():\n",
    "        if not k_densecl.startswith(prefix):\n",
    "            continue\n",
    "        short = k_densecl.replace(prefix, '')  # conv1.weight / bn1.weight / layer1.0.conv1.weight\n",
    "\n",
    "        # Conv1/Bn1 (iniziali)\n",
    "        if short.startswith('conv1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.0\" + short[len('conv1'):]\n",
    "        elif short.startswith('bn1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.1\" + short[len('bn1'):]\n",
    "        # Blocchi layer1-4\n",
    "        elif short.startswith('layer'):\n",
    "            m = re.match(r\"layer(\\d)\\.(\\d+)\\.(.*)\", short)\n",
    "            if not m:\n",
    "                skipped.append((k_densecl, \"no regex match\"))\n",
    "                continue\n",
    "            block_num, block_idx, sublayer = m.groups()\n",
    "            k_ica = f\"model.{ica_offset + int(block_num)}.layer.{block_idx}.{sublayer}\"\n",
    "            k_ica = k_ica.replace('downsample', 'shortcut')\n",
    "        else:\n",
    "            skipped.append((k_densecl, \"no mapping rule\"))\n",
    "            continue\n",
    "\n",
    "        if k_ica in icafusion_state_dict and icafusion_state_dict[k_ica].shape == v_densecl.shape:\n",
    "            new_state_dict[k_ica] = v_densecl\n",
    "            matched.append((k_densecl, k_ica))\n",
    "        else:\n",
    "            skipped.append((k_densecl, k_ica))\n",
    "\n",
    "    print(f\"[DenseCL dom: {domain}] Matchati: {len(matched)}. Saltati: {len(skipped)}\")\n",
    "    if len(matched) < 10:\n",
    "        print(\"Esempi matching:\", matched)\n",
    "    if skipped:\n",
    "        print(\"Esempi saltati:\", skipped[:10])\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f71562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DenseCL dom: visible] Matchati: 318. Saltati: 0\n"
     ]
    }
   ],
   "source": [
    "# primo blocco visible, aggiorna la prima backbone ICA da model.0-4\n",
    "new_icafusion_state_dict_from_denseCL = map_densecl_to_ica(icafusion_model_state_dict, densecl_model_state_dict, domain='visible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e675358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DenseCL dom: infrared] Matchati: 318. Saltati: 0\n"
     ]
    }
   ],
   "source": [
    "# simulo secondo blocco infrared anche se difatto non ho un altro denseCL trainato su infrared ma tanto qui i pesi non importano\n",
    "# aggiorna la seconda backbone ICA da model.5-9\n",
    "new_icafusion_state_dict_from_denseCL = map_densecl_to_ica(new_icafusion_state_dict_from_denseCL, densecl_model_state_dict, domain='infrared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d1851",
   "metadata": {},
   "source": [
    "Stampa primi layer ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9303b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ICAFUSION MODEL STATE_DICT (primi 10 layer) ---\n",
      "[000] model.0.layer.0.weight                             torch.Size([64, 3, 7, 7])\n",
      "[001] model.0.layer.1.weight                             torch.Size([64])\n",
      "[002] model.0.layer.1.bias                               torch.Size([64])\n",
      "[003] model.0.layer.1.running_mean                       torch.Size([64])\n",
      "[004] model.0.layer.1.running_var                        torch.Size([64])\n",
      "[005] model.0.layer.1.num_batches_tracked                torch.Size([])\n",
      "[006] model.1.layer.0.conv1.weight                       torch.Size([64, 64, 1, 1])\n",
      "[007] model.1.layer.0.bn1.weight                         torch.Size([64])\n",
      "[008] model.1.layer.0.bn1.bias                           torch.Size([64])\n",
      "[009] model.1.layer.0.bn1.running_mean                   torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print_first_layers(new_icafusion_state_dict_from_denseCL, n=10, title=\"ICAFUSION MODEL STATE_DICT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27999c9d",
   "metadata": {},
   "source": [
    "Stampa pesi alcuni layer, qui non possiamo correre per indice ma confrontiamo per key name dallo stesso mapping di prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2767e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_densecl_ica_comparison(densecl_state_dict, ica_state_dict, domain='visible', max_print=20):\n",
    "    \"\"\"\n",
    "    Confronta i pesi tra DenseCL (encoder_q) e ICAfusion per i layer omologhi della backbone.\n",
    "    'domain' indica quale backbone ICA usare ('visible' => model.0~4, 'infrared' => model.5~9)\n",
    "    \"\"\"\n",
    "    prefix = \"module.encoder_q.0.\"\n",
    "    ica_offset = 0 if domain == 'visible' else 5\n",
    "    print_count = 0\n",
    "\n",
    "    for k_densecl, v_densecl in densecl_state_dict.items():\n",
    "        if not k_densecl.startswith(prefix):\n",
    "            continue\n",
    "        short = k_densecl.replace(prefix, '')\n",
    "        # Mappatura chiavi:\n",
    "        if short.startswith('conv1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.0\" + short[len('conv1'):]\n",
    "        elif short.startswith('bn1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.1\" + short[len('bn1'):]\n",
    "        elif short.startswith('layer'):\n",
    "            m = re.match(r\"layer(\\d)\\.(\\d+)\\.(.*)\", short)\n",
    "            if not m:\n",
    "                continue\n",
    "            block_num, block_idx, sublayer = m.groups()\n",
    "            k_ica = f\"model.{ica_offset + int(block_num)}.layer.{block_idx}.{sublayer}\"\n",
    "            k_ica = k_ica.replace('downsample', 'shortcut')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if k_ica in ica_state_dict and v_densecl.shape == ica_state_dict[k_ica].shape:\n",
    "            vals_densecl = v_densecl.flatten()[:5].tolist()\n",
    "            vals_ica = ica_state_dict[k_ica].flatten()[:5].tolist()\n",
    "            print(f\"{k_densecl:45s} <=> {k_ica:45s}\")\n",
    "            print(f\"    DenseCL: {vals_densecl}\")\n",
    "            print(f\"    ICAfusion: {vals_ica}\\n\")\n",
    "            print_count += 1\n",
    "            if print_count >= max_print:\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c3d1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.encoder_q.0.conv1.weight               <=> model.0.layer.0.weight                       \n",
      "    DenseCL: [0.011139999143779278, 0.011798703111708164, -0.019292229786515236, -0.025255585089325905, -0.04298553988337517]\n",
      "    ICAfusion: [0.011139999143779278, 0.011798703111708164, -0.019292229786515236, -0.025255585089325905, -0.04298553988337517]\n",
      "\n",
      "module.encoder_q.0.bn1.weight                 <=> model.0.layer.1.weight                       \n",
      "    DenseCL: [0.23528258502483368, 0.29211288690567017, 0.3233895003795624, 0.272586852312088, 0.21750298142433167]\n",
      "    ICAfusion: [0.23528258502483368, 0.29211288690567017, 0.3233895003795624, 0.272586852312088, 0.21750298142433167]\n",
      "\n",
      "module.encoder_q.0.bn1.bias                   <=> model.0.layer.1.bias                         \n",
      "    DenseCL: [0.222642183303833, 0.6056613326072693, 0.014600022695958614, 0.1303965002298355, 0.18065273761749268]\n",
      "    ICAfusion: [0.222642183303833, 0.6056613326072693, 0.014600022695958614, 0.1303965002298355, 0.18065273761749268]\n",
      "\n",
      "module.encoder_q.0.bn1.running_mean           <=> model.0.layer.1.running_mean                 \n",
      "    DenseCL: [0.3382229208946228, 0.09706754982471466, 0.9788333177566528, -0.25482937693595886, -0.16714738309383392]\n",
      "    ICAfusion: [0.3382229208946228, 0.09706754982471466, 0.9788333177566528, -0.25482937693595886, -0.16714738309383392]\n",
      "\n",
      "module.encoder_q.0.bn1.running_var            <=> model.0.layer.1.running_var                  \n",
      "    DenseCL: [0.9258213043212891, 1.4001351594924927, 1.6020793914794922, 3.9225926399230957, 0.5442233681678772]\n",
      "    ICAfusion: [0.9258213043212891, 1.4001351594924927, 1.6020793914794922, 3.9225926399230957, 0.5442233681678772]\n",
      "\n",
      "module.encoder_q.0.bn1.num_batches_tracked    <=> model.0.layer.1.num_batches_tracked          \n",
      "    DenseCL: [365]\n",
      "    ICAfusion: [365]\n",
      "\n",
      "module.encoder_q.0.layer1.0.conv1.weight      <=> model.1.layer.0.conv1.weight                 \n",
      "    DenseCL: [0.0033713560551404953, 0.04112502187490463, -0.02515600435435772, -0.02537056989967823, 0.0891847312450409]\n",
      "    ICAfusion: [0.0033713560551404953, 0.04112502187490463, -0.02515600435435772, -0.02537056989967823, 0.0891847312450409]\n",
      "\n",
      "module.encoder_q.0.layer1.0.bn1.weight        <=> model.1.layer.0.bn1.weight                   \n",
      "    DenseCL: [0.2199483960866928, 0.19332446157932281, 0.14877291023731232, 0.15687154233455658, 0.13835203647613525]\n",
      "    ICAfusion: [0.2199483960866928, 0.19332446157932281, 0.14877291023731232, 0.15687154233455658, 0.13835203647613525]\n",
      "\n",
      "module.encoder_q.0.layer1.0.bn1.bias          <=> model.1.layer.0.bn1.bias                     \n",
      "    DenseCL: [0.4319017231464386, 0.058129921555519104, -0.08176667988300323, 0.07880520075559616, 0.2850973308086395]\n",
      "    ICAfusion: [0.4319017231464386, 0.058129921555519104, -0.08176667988300323, 0.07880520075559616, 0.2850973308086395]\n",
      "\n",
      "module.encoder_q.0.layer1.0.bn1.running_mean  <=> model.1.layer.0.bn1.running_mean             \n",
      "    DenseCL: [-0.6003798246383667, -0.33066943287849426, 0.27932772040367126, -0.2942553460597992, -0.11720377206802368]\n",
      "    ICAfusion: [-0.6003798246383667, -0.33066943287849426, 0.27932772040367126, -0.2942553460597992, -0.11720377206802368]\n",
      "\n",
      "module.encoder_q.0.conv1.weight               <=> model.5.layer.0.weight                       \n",
      "    DenseCL: [0.011139999143779278, 0.011798703111708164, -0.019292229786515236, -0.025255585089325905, -0.04298553988337517]\n",
      "    ICAfusion: [0.011139999143779278, 0.011798703111708164, -0.019292229786515236, -0.025255585089325905, -0.04298553988337517]\n",
      "\n",
      "module.encoder_q.0.bn1.weight                 <=> model.5.layer.1.weight                       \n",
      "    DenseCL: [0.23528258502483368, 0.29211288690567017, 0.3233895003795624, 0.272586852312088, 0.21750298142433167]\n",
      "    ICAfusion: [0.23528258502483368, 0.29211288690567017, 0.3233895003795624, 0.272586852312088, 0.21750298142433167]\n",
      "\n",
      "module.encoder_q.0.bn1.bias                   <=> model.5.layer.1.bias                         \n",
      "    DenseCL: [0.222642183303833, 0.6056613326072693, 0.014600022695958614, 0.1303965002298355, 0.18065273761749268]\n",
      "    ICAfusion: [0.222642183303833, 0.6056613326072693, 0.014600022695958614, 0.1303965002298355, 0.18065273761749268]\n",
      "\n",
      "module.encoder_q.0.bn1.running_mean           <=> model.5.layer.1.running_mean                 \n",
      "    DenseCL: [0.3382229208946228, 0.09706754982471466, 0.9788333177566528, -0.25482937693595886, -0.16714738309383392]\n",
      "    ICAfusion: [0.3382229208946228, 0.09706754982471466, 0.9788333177566528, -0.25482937693595886, -0.16714738309383392]\n",
      "\n",
      "module.encoder_q.0.bn1.running_var            <=> model.5.layer.1.running_var                  \n",
      "    DenseCL: [0.9258213043212891, 1.4001351594924927, 1.6020793914794922, 3.9225926399230957, 0.5442233681678772]\n",
      "    ICAfusion: [0.9258213043212891, 1.4001351594924927, 1.6020793914794922, 3.9225926399230957, 0.5442233681678772]\n",
      "\n",
      "module.encoder_q.0.bn1.num_batches_tracked    <=> model.5.layer.1.num_batches_tracked          \n",
      "    DenseCL: [365]\n",
      "    ICAfusion: [365]\n",
      "\n",
      "module.encoder_q.0.layer1.0.conv1.weight      <=> model.6.layer.0.conv1.weight                 \n",
      "    DenseCL: [0.0033713560551404953, 0.04112502187490463, -0.02515600435435772, -0.02537056989967823, 0.0891847312450409]\n",
      "    ICAfusion: [0.0033713560551404953, 0.04112502187490463, -0.02515600435435772, -0.02537056989967823, 0.0891847312450409]\n",
      "\n",
      "module.encoder_q.0.layer1.0.bn1.weight        <=> model.6.layer.0.bn1.weight                   \n",
      "    DenseCL: [0.2199483960866928, 0.19332446157932281, 0.14877291023731232, 0.15687154233455658, 0.13835203647613525]\n",
      "    ICAfusion: [0.2199483960866928, 0.19332446157932281, 0.14877291023731232, 0.15687154233455658, 0.13835203647613525]\n",
      "\n",
      "module.encoder_q.0.layer1.0.bn1.bias          <=> model.6.layer.0.bn1.bias                     \n",
      "    DenseCL: [0.4319017231464386, 0.058129921555519104, -0.08176667988300323, 0.07880520075559616, 0.2850973308086395]\n",
      "    ICAfusion: [0.4319017231464386, 0.058129921555519104, -0.08176667988300323, 0.07880520075559616, 0.2850973308086395]\n",
      "\n",
      "module.encoder_q.0.layer1.0.bn1.running_mean  <=> model.6.layer.0.bn1.running_mean             \n",
      "    DenseCL: [-0.6003798246383667, -0.33066943287849426, 0.27932772040367126, -0.2942553460597992, -0.11720377206802368]\n",
      "    ICAfusion: [-0.6003798246383667, -0.33066943287849426, 0.27932772040367126, -0.2942553460597992, -0.11720377206802368]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Esempio per branch VISIVILE\n",
    "print_densecl_ica_comparison(densecl_model_state_dict, new_icafusion_state_dict_from_denseCL, domain='visible', max_print=10)\n",
    "# Esempio per branch INFRARED\n",
    "print_densecl_ica_comparison(densecl_model_state_dict, new_icafusion_state_dict_from_denseCL, domain='infrared', max_print=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c074b998",
   "metadata": {},
   "source": [
    "### DenseDeCUR to ICA\n",
    "DenseDeCUR:\n",
    "\n",
    "module.mod1.encoder_q → ICAFusion backbone 1 (model.0~4.*, dominio visible)\n",
    "\n",
    "module.mod2.encoder_q → ICAFusion backbone 2 (model.5~9.*, dominio infrared)\n",
    "\n",
    "\n",
    "ICAFusion:\n",
    "\n",
    "model.0.*, model.1.*, ..., model.4.* → Backbone 1  --  PER VISIBLE VERIFICATO  \n",
    "(inizio a 64, 3, 7, 7 → tipica conv1)\n",
    "\n",
    "model.5.*, model.6.*, ..., model.9.* → Backbone 2  --  PER INFRARED VERIFICATO  \n",
    "(inizio a 64, 3, 7, 7 → tipica conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02976296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def map_dense_decur_to_ica(icafusion_state_dict, decdecur_state_dict, mod=1):\n",
    "    \"\"\"\n",
    "    Popola la backbone ICAFusion dal DenseDeCUR.\n",
    "    - mod=1: usa encoder_q di mod1 → backbone_1 (model.0~4)\n",
    "    - mod=2: usa encoder_q di mod2 → backbone_2 (model.5~9)\n",
    "    \"\"\"\n",
    "    prefix = f\"module.mod{mod}.encoder_q.0.\"     # prefisso per mod1 o mod2 per capire quale target backbone ICA usare\n",
    "    ica_offset = 0 if mod == 1 else 5\n",
    "    new_state_dict = icafusion_state_dict.copy()\n",
    "    matched, skipped = [], []\n",
    "\n",
    "    for k_src, v_src in decdecur_state_dict.items():\n",
    "        if not k_src.startswith(prefix):\n",
    "            continue\n",
    "        short = k_src.replace(prefix, '')\n",
    "\n",
    "        # Mappature semantiche per ResNet backbone (come fatto per DenseCL)\n",
    "        if short.startswith('conv1'):\n",
    "            k_tgt = f\"model.{ica_offset}.layer.0{short[len('conv1'):]}\"\n",
    "        elif short.startswith('bn1'):\n",
    "            k_tgt = f\"model.{ica_offset}.layer.1{short[len('bn1'):]}\"\n",
    "        elif short.startswith('layer'):\n",
    "            m = re.match(r\"layer(\\d)\\.(\\d+)\\.(.*)\", short)\n",
    "            if not m:\n",
    "                skipped.append((k_src, 'no regex match'))\n",
    "                continue\n",
    "            block, idx, rest = m.groups()\n",
    "            k_tgt = f\"model.{ica_offset + int(block)}.layer.{idx}.{rest}\"\n",
    "            k_tgt = k_tgt.replace(\"downsample\", \"shortcut\")\n",
    "        else:\n",
    "            skipped.append((k_src, \"no mapping rule\"))\n",
    "            continue\n",
    "\n",
    "        # Match shape finale \n",
    "        if k_tgt in icafusion_state_dict and v_src.shape == icafusion_state_dict[k_tgt].shape:\n",
    "            new_state_dict[k_tgt] = v_src\n",
    "            matched.append((k_src, k_tgt))\n",
    "        else:\n",
    "            skipped.append((k_src, k_tgt))\n",
    "\n",
    "    print(f\"[DenseDeCUR Mod {mod}] Matchati: {len(matched)}, Saltati: {len(skipped)}\")\n",
    "    \n",
    "\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f7adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DenseDeCUR Mod 1] Matchati: 318, Saltati: 0\n"
     ]
    }
   ],
   "source": [
    "icafusion_model_state_dict_denseDecur = map_dense_decur_to_ica(icafusion_model_state_dict, densecur_model_state_dict, mod=1) # mod=1 per visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbdb11ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DenseDeCUR Mod 2] Matchati: 318, Saltati: 0\n"
     ]
    }
   ],
   "source": [
    "# per secondo passaggio ricordati di passare il risultato della prima run ovvero icafusion_model_state_dict_denseDecur\n",
    "\n",
    "icafusion_model_state_dict_denseDecur = map_dense_decur_to_ica(icafusion_model_state_dict_denseDecur, densecur_model_state_dict, mod=2) # mod=2 per infrared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ac0943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def print_densedecur_ica_comparison(densedecur_state_dict, ica_state_dict, mod=1, max_print=20):\n",
    "    \"\"\"\n",
    "    Confronta i pesi tra DenseDeCUR (encoder_q di mod1/mod2) e ICAfusion per i layer omologhi della backbone.\n",
    "    mod=1: confronta module.mod1.encoder_q.0.* <=> ICA model.0~4.*\n",
    "    mod=2: confronta module.mod2.encoder_q.0.* <=> ICA model.5~9.*\n",
    "    \"\"\"\n",
    "    prefix = f\"module.mod{mod}.encoder_q.0.\"\n",
    "    ica_offset = 0 if mod == 1 else 5\n",
    "    print_count = 0\n",
    "\n",
    "    for k_dense, v_dense in densedecur_state_dict.items():\n",
    "        if not k_dense.startswith(prefix):\n",
    "            continue\n",
    "        short = k_dense.replace(prefix, '')\n",
    "        # Mappatura chiavi:\n",
    "        if short.startswith('conv1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.0\" + short[len('conv1'):]\n",
    "        elif short.startswith('bn1'):\n",
    "            k_ica = f\"model.{ica_offset}.layer.1\" + short[len('bn1'):]\n",
    "        elif short.startswith('layer'):\n",
    "            m = re.match(r\"layer(\\d)\\.(\\d+)\\.(.*)\", short)\n",
    "            if not m:\n",
    "                continue\n",
    "            block_num, block_idx, sublayer = m.groups()\n",
    "            k_ica = f\"model.{ica_offset + int(block_num)}.layer.{block_idx}.{sublayer}\"\n",
    "            k_ica = k_ica.replace('downsample', 'shortcut')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if k_ica in ica_state_dict and v_dense.shape == ica_state_dict[k_ica].shape:\n",
    "            vals_dense = v_dense.flatten()[:5].tolist()\n",
    "            vals_ica = ica_state_dict[k_ica].flatten()[:5].tolist()\n",
    "            print(f\"{k_dense:55s} <=> {k_ica:45s}\")\n",
    "            print(f\"    DenseDeCUR: {vals_dense}\")\n",
    "            print(f\"    ICAfusion:  {vals_ica}\\n\")\n",
    "            print_count += 1\n",
    "            if print_count >= max_print:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e88a7447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.mod1.encoder_q.0.conv1.weight                    <=> model.0.layer.0.weight                       \n",
      "    DenseDeCUR: [0.013406818732619286, 0.01471713650971651, -0.015291975811123848, -0.022917883470654488, -0.04084588959813118]\n",
      "    ICAfusion:  [0.013406818732619286, 0.01471713650971651, -0.015291975811123848, -0.022917883470654488, -0.04084588959813118]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.weight                      <=> model.0.layer.1.weight                       \n",
      "    DenseDeCUR: [0.23711252212524414, 0.2463444620370865, 0.33873045444488525, 0.3013361394405365, 0.14561231434345245]\n",
      "    ICAfusion:  [0.23711252212524414, 0.2463444620370865, 0.33873045444488525, 0.3013361394405365, 0.14561231434345245]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.bias                        <=> model.0.layer.1.bias                         \n",
      "    DenseDeCUR: [0.22382982075214386, 0.6235921382904053, 0.06124328449368477, 0.141941100358963, 0.1804104745388031]\n",
      "    ICAfusion:  [0.22382982075214386, 0.6235921382904053, 0.06124328449368477, 0.141941100358963, 0.1804104745388031]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.running_mean                <=> model.0.layer.1.running_mean                 \n",
      "    DenseDeCUR: [0.13234542310237885, 0.12470265477895737, 1.1110363006591797, -0.131943017244339, -0.070379339158535]\n",
      "    ICAfusion:  [0.13234542310237885, 0.12470265477895737, 1.1110363006591797, -0.131943017244339, -0.070379339158535]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.running_var                 <=> model.0.layer.1.running_var                  \n",
      "    DenseDeCUR: [0.7357009649276733, 1.1630104780197144, 1.7590787410736084, 3.7991750240325928, 0.4302455484867096]\n",
      "    ICAfusion:  [0.7357009649276733, 1.1630104780197144, 1.7590787410736084, 3.7991750240325928, 0.4302455484867096]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.num_batches_tracked         <=> model.0.layer.1.num_batches_tracked          \n",
      "    DenseDeCUR: [365]\n",
      "    ICAfusion:  [365]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.conv1.weight           <=> model.1.layer.0.conv1.weight                 \n",
      "    DenseDeCUR: [0.003525426611304283, 0.03986334428191185, -0.02479557693004608, -0.027785250917077065, 0.08889053761959076]\n",
      "    ICAfusion:  [0.003525426611304283, 0.03986334428191185, -0.02479557693004608, -0.027785250917077065, 0.08889053761959076]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.bn1.weight             <=> model.1.layer.0.bn1.weight                   \n",
      "    DenseDeCUR: [0.16457849740982056, 0.17449581623077393, 0.20205606520175934, 0.14830559492111206, 0.17417000234127045]\n",
      "    ICAfusion:  [0.16457849740982056, 0.17449581623077393, 0.20205606520175934, 0.14830559492111206, 0.17417000234127045]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.bn1.bias               <=> model.1.layer.0.bn1.bias                     \n",
      "    DenseDeCUR: [0.460193932056427, -0.03169002756476402, -0.06085263937711716, 0.11738814413547516, 0.25138407945632935]\n",
      "    ICAfusion:  [0.460193932056427, -0.03169002756476402, -0.06085263937711716, 0.11738814413547516, 0.25138407945632935]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.bn1.running_mean       <=> model.1.layer.0.bn1.running_mean             \n",
      "    DenseDeCUR: [-0.5390883088111877, -0.2985123097896576, 0.2766578197479248, -0.29329901933670044, -0.15242332220077515]\n",
      "    ICAfusion:  [-0.5390883088111877, -0.2985123097896576, 0.2766578197479248, -0.29329901933670044, -0.15242332220077515]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_densedecur_ica_comparison(densecur_model_state_dict, icafusion_model_state_dict_denseDecur, mod=1, max_print=10)  # visible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ece477",
   "metadata": {},
   "source": [
    "### Test salvataggio in memoria del nuovo icafusion_model_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ca9cb",
   "metadata": {},
   "source": [
    "```\n",
    "Importate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db39755",
   "metadata": {},
   "source": [
    "Qui ora dovremo salvare il model_state_dict dentro uno state_dict piu generale, annotando il model_state_dict sotto la chiave 'model'   \n",
    "per seguire la tecnica di caricamento e ricerca del model_state_dict di ICAFusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3358e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Salvataggio dello state_dict completo del modello ICAfusion\n",
    "# Pronto per essere usato in training/finetuning tramite train.py\n",
    "# (Il file sarà salvato in formato compatibile: {'model': <state_dict>})\n",
    "# ===========================================================\n",
    "\n",
    "# si consiglia come path di mettere come target la cartella ICAfusion/final_checkpoints/ \n",
    "# e di salvare i diversi final checkpoint con nomi diversi siginificativi \n",
    "# esempio: icafusion_from_densecur.pth  o icafusion_from_densecl.pth  o icafusion_from_decur.pth\n",
    "\n",
    "import torch\n",
    "\n",
    "def save_icafusion_state_dict_wrapped(icafusion_state_dict, save_path=\"ICAFusion/final_checkpoints/icafusion_from_densecur.pth\"):\n",
    "   \n",
    "    to_save = {'model': icafusion_state_dict}\n",
    "    torch.save(to_save, save_path)\n",
    "    print(f\"Checkpoint ICAfusion salvato come: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7ad8a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint ICAfusion salvato come: ICAFusion/final_checkpoints/icafusion_from_densecur.pth\n"
     ]
    }
   ],
   "source": [
    "# ora per test sceglo di salvare il modello ottenuto da DenseDeCUR\n",
    "\n",
    "save_icafusion_state_dict_wrapped(icafusion_model_state_dict_denseDecur, save_path=\"ICAFusion/final_checkpoints/icafusion_from_densecur.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ffa15f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.mod2.encoder_q.0.conv1.weight                    <=> model.5.layer.0.weight                       \n",
      "    DenseDeCUR: [0.013337275944650173, 0.014666294679045677, -0.015349669381976128, -0.02296222373843193, -0.040896426886320114]\n",
      "    ICAfusion:  [0.013337275944650173, 0.014666294679045677, -0.015349669381976128, -0.02296222373843193, -0.040896426886320114]\n",
      "\n",
      "module.mod2.encoder_q.0.bn1.weight                      <=> model.5.layer.1.weight                       \n",
      "    DenseDeCUR: [0.33419179916381836, 0.44534042477607727, 0.27012649178504944, 0.3975720703601837, 0.12242994457483292]\n",
      "    ICAfusion:  [0.33419179916381836, 0.44534042477607727, 0.27012649178504944, 0.3975720703601837, 0.12242994457483292]\n",
      "\n",
      "module.mod2.encoder_q.0.bn1.bias                        <=> model.5.layer.1.bias                         \n",
      "    DenseDeCUR: [0.22765377163887024, 0.6137559413909912, -0.0776800662279129, 0.15509438514709473, 0.18050257861614227]\n",
      "    ICAfusion:  [0.22765377163887024, 0.6137559413909912, -0.0776800662279129, 0.15509438514709473, 0.18050257861614227]\n",
      "\n",
      "module.mod2.encoder_q.0.bn1.running_mean                <=> model.5.layer.1.running_mean                 \n",
      "    DenseDeCUR: [-0.02509290911257267, 0.03288882598280907, -0.23272131383419037, 0.021315481513738632, 0.011653289198875427]\n",
      "    ICAfusion:  [-0.02509290911257267, 0.03288882598280907, -0.23272131383419037, 0.021315481513738632, 0.011653289198875427]\n",
      "\n",
      "module.mod2.encoder_q.0.bn1.running_var                 <=> model.5.layer.1.running_var                  \n",
      "    DenseDeCUR: [0.00143760337959975, 9.213041630573571e-05, 0.004572831094264984, 0.009011376649141312, 0.00028424293850548565]\n",
      "    ICAfusion:  [0.00143760337959975, 9.213041630573571e-05, 0.004572831094264984, 0.009011376649141312, 0.00028424293850548565]\n",
      "\n",
      "module.mod2.encoder_q.0.bn1.num_batches_tracked         <=> model.5.layer.1.num_batches_tracked          \n",
      "    DenseDeCUR: [365]\n",
      "    ICAfusion:  [365]\n",
      "\n",
      "module.mod2.encoder_q.0.layer1.0.conv1.weight           <=> model.6.layer.0.conv1.weight                 \n",
      "    DenseDeCUR: [0.003529977984726429, 0.039846401661634445, -0.024803897365927696, -0.027836482971906662, 0.08888399600982666]\n",
      "    ICAfusion:  [0.003529977984726429, 0.039846401661634445, -0.024803897365927696, -0.027836482971906662, 0.08888399600982666]\n",
      "\n",
      "module.mod2.encoder_q.0.layer1.0.bn1.weight             <=> model.6.layer.0.bn1.weight                   \n",
      "    DenseDeCUR: [0.31096863746643066, 0.27425119280815125, 0.2633759677410126, 0.22854715585708618, 0.11759771406650543]\n",
      "    ICAfusion:  [0.31096863746643066, 0.27425119280815125, 0.2633759677410126, 0.22854715585708618, 0.11759771406650543]\n",
      "\n",
      "module.mod2.encoder_q.0.layer1.0.bn1.bias               <=> model.6.layer.0.bn1.bias                     \n",
      "    DenseDeCUR: [0.48710131645202637, -0.0673687681555748, -0.062319960445165634, -0.04304804652929306, 0.31070080399513245]\n",
      "    ICAfusion:  [0.48710131645202637, -0.0673687681555748, -0.062319960445165634, -0.04304804652929306, 0.31070080399513245]\n",
      "\n",
      "module.mod2.encoder_q.0.layer1.0.bn1.running_mean       <=> model.6.layer.0.bn1.running_mean             \n",
      "    DenseDeCUR: [-0.6447049379348755, -0.3493749797344208, 0.21378615498542786, -0.21533729135990143, -0.12219911813735962]\n",
      "    ICAfusion:  [-0.6447049379348755, -0.3493749797344208, 0.21378615498542786, -0.21533729135990143, -0.12219911813735962]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_densedecur_ica_comparison(densecur_model_state_dict, icafusion_model_state_dict_denseDecur, mod=2, max_print=10)  # visible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d83bf",
   "metadata": {},
   "source": [
    "### Confronto finale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5911ea",
   "metadata": {},
   "source": [
    "Scarico da train.py di ICAFusion il model_state_dict di ICA DOPO aver completato il caricamento da pretraining. [ icafusion_state_dict_AFTER_LOAD ]  \n",
    "\n",
    " \n",
    " Essendo:  \n",
    "   \n",
    "            densecur_model_state_dict -> icafusion_model_state_dict_denseDecur --> icafusion_state_dict_AFTER_LOAD.pth       \n",
    " \n",
    " SE densecur_model_state_dict == icafusion_state_dict_AFTER_LOAD   \n",
    " ALLORA confermo consistenza tra \n",
    " * mapping da densecur_model_state_dict -> icafusion_model_state_dict_denseDecur\n",
    " * copia da icafusion_model_state_dict_denseDecur -> icafusion_state_dict_AFTER_LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b22fda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_925/2543900089.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d1 = torch.load(pth1, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['model.0.layer.0.weight', 'model.0.layer.1.weight', 'model.0.layer.1.bias', 'model.0.layer.1.running_mean', 'model.0.layer.1.running_var', 'model.0.layer.1.num_batches_tracked', 'model.1.layer.0.conv1.weight', 'model.1.layer.0.bn1.weight', 'model.1.layer.0.bn1.bias', 'model.1.layer.0.bn1.running_mean', 'model.1.layer.0.bn1.running_var', 'model.1.layer.0.bn1.num_batches_tracked', 'model.1.layer.0.conv2.weight', 'model.1.layer.0.bn2.weight', 'model.1.layer.0.bn2.bias', 'model.1.layer.0.bn2.running_mean', 'model.1.layer.0.bn2.running_var', 'model.1.layer.0.bn2.num_batches_tracked', 'model.1.layer.0.conv3.weight', 'model.1.layer.0.bn3.weight', 'model.1.layer.0.bn3.bias', 'model.1.layer.0.bn3.running_mean', 'model.1.layer.0.bn3.running_var', 'model.1.layer.0.bn3.num_batches_tracked', 'model.1.layer.0.shortcut.0.weight', 'model.1.layer.0.shortcut.1.weight', 'model.1.layer.0.shortcut.1.bias', 'model.1.layer.0.shortcut.1.running_mean', 'model.1.layer.0.shortcut.1.running_var', 'model.1.layer.0.shortcut.1.num_batches_tracked', 'model.1.layer.1.conv1.weight', 'model.1.layer.1.bn1.weight', 'model.1.layer.1.bn1.bias', 'model.1.layer.1.bn1.running_mean', 'model.1.layer.1.bn1.running_var', 'model.1.layer.1.bn1.num_batches_tracked', 'model.1.layer.1.conv2.weight', 'model.1.layer.1.bn2.weight', 'model.1.layer.1.bn2.bias', 'model.1.layer.1.bn2.running_mean', 'model.1.layer.1.bn2.running_var', 'model.1.layer.1.bn2.num_batches_tracked', 'model.1.layer.1.conv3.weight', 'model.1.layer.1.bn3.weight', 'model.1.layer.1.bn3.bias', 'model.1.layer.1.bn3.running_mean', 'model.1.layer.1.bn3.running_var', 'model.1.layer.1.bn3.num_batches_tracked', 'model.1.layer.2.conv1.weight', 'model.1.layer.2.bn1.weight', 'model.1.layer.2.bn1.bias', 'model.1.layer.2.bn1.running_mean', 'model.1.layer.2.bn1.running_var', 'model.1.layer.2.bn1.num_batches_tracked', 'model.1.layer.2.conv2.weight', 'model.1.layer.2.bn2.weight', 'model.1.layer.2.bn2.bias', 'model.1.layer.2.bn2.running_mean', 'model.1.layer.2.bn2.running_var', 'model.1.layer.2.bn2.num_batches_tracked', 'model.1.layer.2.conv3.weight', 'model.1.layer.2.bn3.weight', 'model.1.layer.2.bn3.bias', 'model.1.layer.2.bn3.running_mean', 'model.1.layer.2.bn3.running_var', 'model.1.layer.2.bn3.num_batches_tracked', 'model.2.layer.0.conv1.weight', 'model.2.layer.0.bn1.weight', 'model.2.layer.0.bn1.bias', 'model.2.layer.0.bn1.running_mean', 'model.2.layer.0.bn1.running_var', 'model.2.layer.0.bn1.num_batches_tracked', 'model.2.layer.0.conv2.weight', 'model.2.layer.0.bn2.weight', 'model.2.layer.0.bn2.bias', 'model.2.layer.0.bn2.running_mean', 'model.2.layer.0.bn2.running_var', 'model.2.layer.0.bn2.num_batches_tracked', 'model.2.layer.0.conv3.weight', 'model.2.layer.0.bn3.weight', 'model.2.layer.0.bn3.bias', 'model.2.layer.0.bn3.running_mean', 'model.2.layer.0.bn3.running_var', 'model.2.layer.0.bn3.num_batches_tracked', 'model.2.layer.0.shortcut.0.weight', 'model.2.layer.0.shortcut.1.weight', 'model.2.layer.0.shortcut.1.bias', 'model.2.layer.0.shortcut.1.running_mean', 'model.2.layer.0.shortcut.1.running_var', 'model.2.layer.0.shortcut.1.num_batches_tracked', 'model.2.layer.1.conv1.weight', 'model.2.layer.1.bn1.weight', 'model.2.layer.1.bn1.bias', 'model.2.layer.1.bn1.running_mean', 'model.2.layer.1.bn1.running_var', 'model.2.layer.1.bn1.num_batches_tracked', 'model.2.layer.1.conv2.weight', 'model.2.layer.1.bn2.weight', 'model.2.layer.1.bn2.bias', 'model.2.layer.1.bn2.running_mean', 'model.2.layer.1.bn2.running_var', 'model.2.layer.1.bn2.num_batches_tracked', 'model.2.layer.1.conv3.weight', 'model.2.layer.1.bn3.weight', 'model.2.layer.1.bn3.bias', 'model.2.layer.1.bn3.running_mean', 'model.2.layer.1.bn3.running_var', 'model.2.layer.1.bn3.num_batches_tracked', 'model.2.layer.2.conv1.weight', 'model.2.layer.2.bn1.weight', 'model.2.layer.2.bn1.bias', 'model.2.layer.2.bn1.running_mean', 'model.2.layer.2.bn1.running_var', 'model.2.layer.2.bn1.num_batches_tracked', 'model.2.layer.2.conv2.weight', 'model.2.layer.2.bn2.weight', 'model.2.layer.2.bn2.bias', 'model.2.layer.2.bn2.running_mean', 'model.2.layer.2.bn2.running_var', 'model.2.layer.2.bn2.num_batches_tracked', 'model.2.layer.2.conv3.weight', 'model.2.layer.2.bn3.weight', 'model.2.layer.2.bn3.bias', 'model.2.layer.2.bn3.running_mean', 'model.2.layer.2.bn3.running_var', 'model.2.layer.2.bn3.num_batches_tracked', 'model.2.layer.3.conv1.weight', 'model.2.layer.3.bn1.weight', 'model.2.layer.3.bn1.bias', 'model.2.layer.3.bn1.running_mean', 'model.2.layer.3.bn1.running_var', 'model.2.layer.3.bn1.num_batches_tracked', 'model.2.layer.3.conv2.weight', 'model.2.layer.3.bn2.weight', 'model.2.layer.3.bn2.bias', 'model.2.layer.3.bn2.running_mean', 'model.2.layer.3.bn2.running_var', 'model.2.layer.3.bn2.num_batches_tracked', 'model.2.layer.3.conv3.weight', 'model.2.layer.3.bn3.weight', 'model.2.layer.3.bn3.bias', 'model.2.layer.3.bn3.running_mean', 'model.2.layer.3.bn3.running_var', 'model.2.layer.3.bn3.num_batches_tracked', 'model.3.layer.0.conv1.weight', 'model.3.layer.0.bn1.weight', 'model.3.layer.0.bn1.bias', 'model.3.layer.0.bn1.running_mean', 'model.3.layer.0.bn1.running_var', 'model.3.layer.0.bn1.num_batches_tracked', 'model.3.layer.0.conv2.weight', 'model.3.layer.0.bn2.weight', 'model.3.layer.0.bn2.bias', 'model.3.layer.0.bn2.running_mean', 'model.3.layer.0.bn2.running_var', 'model.3.layer.0.bn2.num_batches_tracked', 'model.3.layer.0.conv3.weight', 'model.3.layer.0.bn3.weight', 'model.3.layer.0.bn3.bias', 'model.3.layer.0.bn3.running_mean', 'model.3.layer.0.bn3.running_var', 'model.3.layer.0.bn3.num_batches_tracked', 'model.3.layer.0.shortcut.0.weight', 'model.3.layer.0.shortcut.1.weight', 'model.3.layer.0.shortcut.1.bias', 'model.3.layer.0.shortcut.1.running_mean', 'model.3.layer.0.shortcut.1.running_var', 'model.3.layer.0.shortcut.1.num_batches_tracked', 'model.3.layer.1.conv1.weight', 'model.3.layer.1.bn1.weight', 'model.3.layer.1.bn1.bias', 'model.3.layer.1.bn1.running_mean', 'model.3.layer.1.bn1.running_var', 'model.3.layer.1.bn1.num_batches_tracked', 'model.3.layer.1.conv2.weight', 'model.3.layer.1.bn2.weight', 'model.3.layer.1.bn2.bias', 'model.3.layer.1.bn2.running_mean', 'model.3.layer.1.bn2.running_var', 'model.3.layer.1.bn2.num_batches_tracked', 'model.3.layer.1.conv3.weight', 'model.3.layer.1.bn3.weight', 'model.3.layer.1.bn3.bias', 'model.3.layer.1.bn3.running_mean', 'model.3.layer.1.bn3.running_var', 'model.3.layer.1.bn3.num_batches_tracked', 'model.3.layer.2.conv1.weight', 'model.3.layer.2.bn1.weight', 'model.3.layer.2.bn1.bias', 'model.3.layer.2.bn1.running_mean', 'model.3.layer.2.bn1.running_var', 'model.3.layer.2.bn1.num_batches_tracked', 'model.3.layer.2.conv2.weight', 'model.3.layer.2.bn2.weight', 'model.3.layer.2.bn2.bias', 'model.3.layer.2.bn2.running_mean', 'model.3.layer.2.bn2.running_var', 'model.3.layer.2.bn2.num_batches_tracked', 'model.3.layer.2.conv3.weight', 'model.3.layer.2.bn3.weight', 'model.3.layer.2.bn3.bias', 'model.3.layer.2.bn3.running_mean', 'model.3.layer.2.bn3.running_var', 'model.3.layer.2.bn3.num_batches_tracked', 'model.3.layer.3.conv1.weight', 'model.3.layer.3.bn1.weight', 'model.3.layer.3.bn1.bias', 'model.3.layer.3.bn1.running_mean', 'model.3.layer.3.bn1.running_var', 'model.3.layer.3.bn1.num_batches_tracked', 'model.3.layer.3.conv2.weight', 'model.3.layer.3.bn2.weight', 'model.3.layer.3.bn2.bias', 'model.3.layer.3.bn2.running_mean', 'model.3.layer.3.bn2.running_var', 'model.3.layer.3.bn2.num_batches_tracked', 'model.3.layer.3.conv3.weight', 'model.3.layer.3.bn3.weight', 'model.3.layer.3.bn3.bias', 'model.3.layer.3.bn3.running_mean', 'model.3.layer.3.bn3.running_var', 'model.3.layer.3.bn3.num_batches_tracked', 'model.3.layer.4.conv1.weight', 'model.3.layer.4.bn1.weight', 'model.3.layer.4.bn1.bias', 'model.3.layer.4.bn1.running_mean', 'model.3.layer.4.bn1.running_var', 'model.3.layer.4.bn1.num_batches_tracked', 'model.3.layer.4.conv2.weight', 'model.3.layer.4.bn2.weight', 'model.3.layer.4.bn2.bias', 'model.3.layer.4.bn2.running_mean', 'model.3.layer.4.bn2.running_var', 'model.3.layer.4.bn2.num_batches_tracked', 'model.3.layer.4.conv3.weight', 'model.3.layer.4.bn3.weight', 'model.3.layer.4.bn3.bias', 'model.3.layer.4.bn3.running_mean', 'model.3.layer.4.bn3.running_var', 'model.3.layer.4.bn3.num_batches_tracked', 'model.3.layer.5.conv1.weight', 'model.3.layer.5.bn1.weight', 'model.3.layer.5.bn1.bias', 'model.3.layer.5.bn1.running_mean', 'model.3.layer.5.bn1.running_var', 'model.3.layer.5.bn1.num_batches_tracked', 'model.3.layer.5.conv2.weight', 'model.3.layer.5.bn2.weight', 'model.3.layer.5.bn2.bias', 'model.3.layer.5.bn2.running_mean', 'model.3.layer.5.bn2.running_var', 'model.3.layer.5.bn2.num_batches_tracked', 'model.3.layer.5.conv3.weight', 'model.3.layer.5.bn3.weight', 'model.3.layer.5.bn3.bias', 'model.3.layer.5.bn3.running_mean', 'model.3.layer.5.bn3.running_var', 'model.3.layer.5.bn3.num_batches_tracked', 'model.4.layer.0.conv1.weight', 'model.4.layer.0.bn1.weight', 'model.4.layer.0.bn1.bias', 'model.4.layer.0.bn1.running_mean', 'model.4.layer.0.bn1.running_var', 'model.4.layer.0.bn1.num_batches_tracked', 'model.4.layer.0.conv2.weight', 'model.4.layer.0.bn2.weight', 'model.4.layer.0.bn2.bias', 'model.4.layer.0.bn2.running_mean', 'model.4.layer.0.bn2.running_var', 'model.4.layer.0.bn2.num_batches_tracked', 'model.4.layer.0.conv3.weight', 'model.4.layer.0.bn3.weight', 'model.4.layer.0.bn3.bias', 'model.4.layer.0.bn3.running_mean', 'model.4.layer.0.bn3.running_var', 'model.4.layer.0.bn3.num_batches_tracked', 'model.4.layer.0.shortcut.0.weight', 'model.4.layer.0.shortcut.1.weight', 'model.4.layer.0.shortcut.1.bias', 'model.4.layer.0.shortcut.1.running_mean', 'model.4.layer.0.shortcut.1.running_var', 'model.4.layer.0.shortcut.1.num_batches_tracked', 'model.4.layer.1.conv1.weight', 'model.4.layer.1.bn1.weight', 'model.4.layer.1.bn1.bias', 'model.4.layer.1.bn1.running_mean', 'model.4.layer.1.bn1.running_var', 'model.4.layer.1.bn1.num_batches_tracked', 'model.4.layer.1.conv2.weight', 'model.4.layer.1.bn2.weight', 'model.4.layer.1.bn2.bias', 'model.4.layer.1.bn2.running_mean', 'model.4.layer.1.bn2.running_var', 'model.4.layer.1.bn2.num_batches_tracked', 'model.4.layer.1.conv3.weight', 'model.4.layer.1.bn3.weight', 'model.4.layer.1.bn3.bias', 'model.4.layer.1.bn3.running_mean', 'model.4.layer.1.bn3.running_var', 'model.4.layer.1.bn3.num_batches_tracked', 'model.4.layer.2.conv1.weight', 'model.4.layer.2.bn1.weight', 'model.4.layer.2.bn1.bias', 'model.4.layer.2.bn1.running_mean', 'model.4.layer.2.bn1.running_var', 'model.4.layer.2.bn1.num_batches_tracked', 'model.4.layer.2.conv2.weight', 'model.4.layer.2.bn2.weight', 'model.4.layer.2.bn2.bias', 'model.4.layer.2.bn2.running_mean', 'model.4.layer.2.bn2.running_var', 'model.4.layer.2.bn2.num_batches_tracked', 'model.4.layer.2.conv3.weight', 'model.4.layer.2.bn3.weight', 'model.4.layer.2.bn3.bias', 'model.4.layer.2.bn3.running_mean', 'model.4.layer.2.bn3.running_var', 'model.4.layer.2.bn3.num_batches_tracked', 'model.5.layer.0.weight', 'model.5.layer.1.weight', 'model.5.layer.1.bias', 'model.5.layer.1.running_mean', 'model.5.layer.1.running_var', 'model.5.layer.1.num_batches_tracked', 'model.6.layer.0.conv1.weight', 'model.6.layer.0.bn1.weight', 'model.6.layer.0.bn1.bias', 'model.6.layer.0.bn1.running_mean', 'model.6.layer.0.bn1.running_var', 'model.6.layer.0.bn1.num_batches_tracked', 'model.6.layer.0.conv2.weight', 'model.6.layer.0.bn2.weight', 'model.6.layer.0.bn2.bias', 'model.6.layer.0.bn2.running_mean', 'model.6.layer.0.bn2.running_var', 'model.6.layer.0.bn2.num_batches_tracked', 'model.6.layer.0.conv3.weight', 'model.6.layer.0.bn3.weight', 'model.6.layer.0.bn3.bias', 'model.6.layer.0.bn3.running_mean', 'model.6.layer.0.bn3.running_var', 'model.6.layer.0.bn3.num_batches_tracked', 'model.6.layer.0.shortcut.0.weight', 'model.6.layer.0.shortcut.1.weight', 'model.6.layer.0.shortcut.1.bias', 'model.6.layer.0.shortcut.1.running_mean', 'model.6.layer.0.shortcut.1.running_var', 'model.6.layer.0.shortcut.1.num_batches_tracked', 'model.6.layer.1.conv1.weight', 'model.6.layer.1.bn1.weight', 'model.6.layer.1.bn1.bias', 'model.6.layer.1.bn1.running_mean', 'model.6.layer.1.bn1.running_var', 'model.6.layer.1.bn1.num_batches_tracked', 'model.6.layer.1.conv2.weight', 'model.6.layer.1.bn2.weight', 'model.6.layer.1.bn2.bias', 'model.6.layer.1.bn2.running_mean', 'model.6.layer.1.bn2.running_var', 'model.6.layer.1.bn2.num_batches_tracked', 'model.6.layer.1.conv3.weight', 'model.6.layer.1.bn3.weight', 'model.6.layer.1.bn3.bias', 'model.6.layer.1.bn3.running_mean', 'model.6.layer.1.bn3.running_var', 'model.6.layer.1.bn3.num_batches_tracked', 'model.6.layer.2.conv1.weight', 'model.6.layer.2.bn1.weight', 'model.6.layer.2.bn1.bias', 'model.6.layer.2.bn1.running_mean', 'model.6.layer.2.bn1.running_var', 'model.6.layer.2.bn1.num_batches_tracked', 'model.6.layer.2.conv2.weight', 'model.6.layer.2.bn2.weight', 'model.6.layer.2.bn2.bias', 'model.6.layer.2.bn2.running_mean', 'model.6.layer.2.bn2.running_var', 'model.6.layer.2.bn2.num_batches_tracked', 'model.6.layer.2.conv3.weight', 'model.6.layer.2.bn3.weight', 'model.6.layer.2.bn3.bias', 'model.6.layer.2.bn3.running_mean', 'model.6.layer.2.bn3.running_var', 'model.6.layer.2.bn3.num_batches_tracked', 'model.7.layer.0.conv1.weight', 'model.7.layer.0.bn1.weight', 'model.7.layer.0.bn1.bias', 'model.7.layer.0.bn1.running_mean', 'model.7.layer.0.bn1.running_var', 'model.7.layer.0.bn1.num_batches_tracked', 'model.7.layer.0.conv2.weight', 'model.7.layer.0.bn2.weight', 'model.7.layer.0.bn2.bias', 'model.7.layer.0.bn2.running_mean', 'model.7.layer.0.bn2.running_var', 'model.7.layer.0.bn2.num_batches_tracked', 'model.7.layer.0.conv3.weight', 'model.7.layer.0.bn3.weight', 'model.7.layer.0.bn3.bias', 'model.7.layer.0.bn3.running_mean', 'model.7.layer.0.bn3.running_var', 'model.7.layer.0.bn3.num_batches_tracked', 'model.7.layer.0.shortcut.0.weight', 'model.7.layer.0.shortcut.1.weight', 'model.7.layer.0.shortcut.1.bias', 'model.7.layer.0.shortcut.1.running_mean', 'model.7.layer.0.shortcut.1.running_var', 'model.7.layer.0.shortcut.1.num_batches_tracked', 'model.7.layer.1.conv1.weight', 'model.7.layer.1.bn1.weight', 'model.7.layer.1.bn1.bias', 'model.7.layer.1.bn1.running_mean', 'model.7.layer.1.bn1.running_var', 'model.7.layer.1.bn1.num_batches_tracked', 'model.7.layer.1.conv2.weight', 'model.7.layer.1.bn2.weight', 'model.7.layer.1.bn2.bias', 'model.7.layer.1.bn2.running_mean', 'model.7.layer.1.bn2.running_var', 'model.7.layer.1.bn2.num_batches_tracked', 'model.7.layer.1.conv3.weight', 'model.7.layer.1.bn3.weight', 'model.7.layer.1.bn3.bias', 'model.7.layer.1.bn3.running_mean', 'model.7.layer.1.bn3.running_var', 'model.7.layer.1.bn3.num_batches_tracked', 'model.7.layer.2.conv1.weight', 'model.7.layer.2.bn1.weight', 'model.7.layer.2.bn1.bias', 'model.7.layer.2.bn1.running_mean', 'model.7.layer.2.bn1.running_var', 'model.7.layer.2.bn1.num_batches_tracked', 'model.7.layer.2.conv2.weight', 'model.7.layer.2.bn2.weight', 'model.7.layer.2.bn2.bias', 'model.7.layer.2.bn2.running_mean', 'model.7.layer.2.bn2.running_var', 'model.7.layer.2.bn2.num_batches_tracked', 'model.7.layer.2.conv3.weight', 'model.7.layer.2.bn3.weight', 'model.7.layer.2.bn3.bias', 'model.7.layer.2.bn3.running_mean', 'model.7.layer.2.bn3.running_var', 'model.7.layer.2.bn3.num_batches_tracked', 'model.7.layer.3.conv1.weight', 'model.7.layer.3.bn1.weight', 'model.7.layer.3.bn1.bias', 'model.7.layer.3.bn1.running_mean', 'model.7.layer.3.bn1.running_var', 'model.7.layer.3.bn1.num_batches_tracked', 'model.7.layer.3.conv2.weight', 'model.7.layer.3.bn2.weight', 'model.7.layer.3.bn2.bias', 'model.7.layer.3.bn2.running_mean', 'model.7.layer.3.bn2.running_var', 'model.7.layer.3.bn2.num_batches_tracked', 'model.7.layer.3.conv3.weight', 'model.7.layer.3.bn3.weight', 'model.7.layer.3.bn3.bias', 'model.7.layer.3.bn3.running_mean', 'model.7.layer.3.bn3.running_var', 'model.7.layer.3.bn3.num_batches_tracked', 'model.8.layer.0.conv1.weight', 'model.8.layer.0.bn1.weight', 'model.8.layer.0.bn1.bias', 'model.8.layer.0.bn1.running_mean', 'model.8.layer.0.bn1.running_var', 'model.8.layer.0.bn1.num_batches_tracked', 'model.8.layer.0.conv2.weight', 'model.8.layer.0.bn2.weight', 'model.8.layer.0.bn2.bias', 'model.8.layer.0.bn2.running_mean', 'model.8.layer.0.bn2.running_var', 'model.8.layer.0.bn2.num_batches_tracked', 'model.8.layer.0.conv3.weight', 'model.8.layer.0.bn3.weight', 'model.8.layer.0.bn3.bias', 'model.8.layer.0.bn3.running_mean', 'model.8.layer.0.bn3.running_var', 'model.8.layer.0.bn3.num_batches_tracked', 'model.8.layer.0.shortcut.0.weight', 'model.8.layer.0.shortcut.1.weight', 'model.8.layer.0.shortcut.1.bias', 'model.8.layer.0.shortcut.1.running_mean', 'model.8.layer.0.shortcut.1.running_var', 'model.8.layer.0.shortcut.1.num_batches_tracked', 'model.8.layer.1.conv1.weight', 'model.8.layer.1.bn1.weight', 'model.8.layer.1.bn1.bias', 'model.8.layer.1.bn1.running_mean', 'model.8.layer.1.bn1.running_var', 'model.8.layer.1.bn1.num_batches_tracked', 'model.8.layer.1.conv2.weight', 'model.8.layer.1.bn2.weight', 'model.8.layer.1.bn2.bias', 'model.8.layer.1.bn2.running_mean', 'model.8.layer.1.bn2.running_var', 'model.8.layer.1.bn2.num_batches_tracked', 'model.8.layer.1.conv3.weight', 'model.8.layer.1.bn3.weight', 'model.8.layer.1.bn3.bias', 'model.8.layer.1.bn3.running_mean', 'model.8.layer.1.bn3.running_var', 'model.8.layer.1.bn3.num_batches_tracked', 'model.8.layer.2.conv1.weight', 'model.8.layer.2.bn1.weight', 'model.8.layer.2.bn1.bias', 'model.8.layer.2.bn1.running_mean', 'model.8.layer.2.bn1.running_var', 'model.8.layer.2.bn1.num_batches_tracked', 'model.8.layer.2.conv2.weight', 'model.8.layer.2.bn2.weight', 'model.8.layer.2.bn2.bias', 'model.8.layer.2.bn2.running_mean', 'model.8.layer.2.bn2.running_var', 'model.8.layer.2.bn2.num_batches_tracked', 'model.8.layer.2.conv3.weight', 'model.8.layer.2.bn3.weight', 'model.8.layer.2.bn3.bias', 'model.8.layer.2.bn3.running_mean', 'model.8.layer.2.bn3.running_var', 'model.8.layer.2.bn3.num_batches_tracked', 'model.8.layer.3.conv1.weight', 'model.8.layer.3.bn1.weight', 'model.8.layer.3.bn1.bias', 'model.8.layer.3.bn1.running_mean', 'model.8.layer.3.bn1.running_var', 'model.8.layer.3.bn1.num_batches_tracked', 'model.8.layer.3.conv2.weight', 'model.8.layer.3.bn2.weight', 'model.8.layer.3.bn2.bias', 'model.8.layer.3.bn2.running_mean', 'model.8.layer.3.bn2.running_var', 'model.8.layer.3.bn2.num_batches_tracked', 'model.8.layer.3.conv3.weight', 'model.8.layer.3.bn3.weight', 'model.8.layer.3.bn3.bias', 'model.8.layer.3.bn3.running_mean', 'model.8.layer.3.bn3.running_var', 'model.8.layer.3.bn3.num_batches_tracked', 'model.8.layer.4.conv1.weight', 'model.8.layer.4.bn1.weight', 'model.8.layer.4.bn1.bias', 'model.8.layer.4.bn1.running_mean', 'model.8.layer.4.bn1.running_var', 'model.8.layer.4.bn1.num_batches_tracked', 'model.8.layer.4.conv2.weight', 'model.8.layer.4.bn2.weight', 'model.8.layer.4.bn2.bias', 'model.8.layer.4.bn2.running_mean', 'model.8.layer.4.bn2.running_var', 'model.8.layer.4.bn2.num_batches_tracked', 'model.8.layer.4.conv3.weight', 'model.8.layer.4.bn3.weight', 'model.8.layer.4.bn3.bias', 'model.8.layer.4.bn3.running_mean', 'model.8.layer.4.bn3.running_var', 'model.8.layer.4.bn3.num_batches_tracked', 'model.8.layer.5.conv1.weight', 'model.8.layer.5.bn1.weight', 'model.8.layer.5.bn1.bias', 'model.8.layer.5.bn1.running_mean', 'model.8.layer.5.bn1.running_var', 'model.8.layer.5.bn1.num_batches_tracked', 'model.8.layer.5.conv2.weight', 'model.8.layer.5.bn2.weight', 'model.8.layer.5.bn2.bias', 'model.8.layer.5.bn2.running_mean', 'model.8.layer.5.bn2.running_var', 'model.8.layer.5.bn2.num_batches_tracked', 'model.8.layer.5.conv3.weight', 'model.8.layer.5.bn3.weight', 'model.8.layer.5.bn3.bias', 'model.8.layer.5.bn3.running_mean', 'model.8.layer.5.bn3.running_var', 'model.8.layer.5.bn3.num_batches_tracked', 'model.9.layer.0.conv1.weight', 'model.9.layer.0.bn1.weight', 'model.9.layer.0.bn1.bias', 'model.9.layer.0.bn1.running_mean', 'model.9.layer.0.bn1.running_var', 'model.9.layer.0.bn1.num_batches_tracked', 'model.9.layer.0.conv2.weight', 'model.9.layer.0.bn2.weight', 'model.9.layer.0.bn2.bias', 'model.9.layer.0.bn2.running_mean', 'model.9.layer.0.bn2.running_var', 'model.9.layer.0.bn2.num_batches_tracked', 'model.9.layer.0.conv3.weight', 'model.9.layer.0.bn3.weight', 'model.9.layer.0.bn3.bias', 'model.9.layer.0.bn3.running_mean', 'model.9.layer.0.bn3.running_var', 'model.9.layer.0.bn3.num_batches_tracked', 'model.9.layer.0.shortcut.0.weight', 'model.9.layer.0.shortcut.1.weight', 'model.9.layer.0.shortcut.1.bias', 'model.9.layer.0.shortcut.1.running_mean', 'model.9.layer.0.shortcut.1.running_var', 'model.9.layer.0.shortcut.1.num_batches_tracked', 'model.9.layer.1.conv1.weight', 'model.9.layer.1.bn1.weight', 'model.9.layer.1.bn1.bias', 'model.9.layer.1.bn1.running_mean', 'model.9.layer.1.bn1.running_var', 'model.9.layer.1.bn1.num_batches_tracked', 'model.9.layer.1.conv2.weight', 'model.9.layer.1.bn2.weight', 'model.9.layer.1.bn2.bias', 'model.9.layer.1.bn2.running_mean', 'model.9.layer.1.bn2.running_var', 'model.9.layer.1.bn2.num_batches_tracked', 'model.9.layer.1.conv3.weight', 'model.9.layer.1.bn3.weight', 'model.9.layer.1.bn3.bias', 'model.9.layer.1.bn3.running_mean', 'model.9.layer.1.bn3.running_var', 'model.9.layer.1.bn3.num_batches_tracked', 'model.9.layer.2.conv1.weight', 'model.9.layer.2.bn1.weight', 'model.9.layer.2.bn1.bias', 'model.9.layer.2.bn1.running_mean', 'model.9.layer.2.bn1.running_var', 'model.9.layer.2.bn1.num_batches_tracked', 'model.9.layer.2.conv2.weight', 'model.9.layer.2.bn2.weight', 'model.9.layer.2.bn2.bias', 'model.9.layer.2.bn2.running_mean', 'model.9.layer.2.bn2.running_var', 'model.9.layer.2.bn2.num_batches_tracked', 'model.9.layer.2.conv3.weight', 'model.9.layer.2.bn3.weight', 'model.9.layer.2.bn3.bias', 'model.9.layer.2.bn3.running_mean', 'model.9.layer.2.bn3.running_var', 'model.9.layer.2.bn3.num_batches_tracked', 'model.10.pos_emb_vis', 'model.10.pos_emb_ir', 'model.10.vis_coefficient.w1', 'model.10.vis_coefficient.w2', 'model.10.ir_coefficient.w1', 'model.10.ir_coefficient.w2', 'model.10.crosstransformer.0.ln_input.weight', 'model.10.crosstransformer.0.ln_input.bias', 'model.10.crosstransformer.0.ln_output.weight', 'model.10.crosstransformer.0.ln_output.bias', 'model.10.crosstransformer.0.crossatt.que_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.que_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.key_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.key_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.val_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.val_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.que_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.que_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.key_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.key_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.val_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.val_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.out_proj_vis.weight', 'model.10.crosstransformer.0.crossatt.out_proj_vis.bias', 'model.10.crosstransformer.0.crossatt.out_proj_ir.weight', 'model.10.crosstransformer.0.crossatt.out_proj_ir.bias', 'model.10.crosstransformer.0.crossatt.LN1.weight', 'model.10.crosstransformer.0.crossatt.LN1.bias', 'model.10.crosstransformer.0.crossatt.LN2.weight', 'model.10.crosstransformer.0.crossatt.LN2.bias', 'model.10.crosstransformer.0.mlp_vis.0.weight', 'model.10.crosstransformer.0.mlp_vis.0.bias', 'model.10.crosstransformer.0.mlp_vis.2.weight', 'model.10.crosstransformer.0.mlp_vis.2.bias', 'model.10.crosstransformer.0.mlp_ir.0.weight', 'model.10.crosstransformer.0.mlp_ir.0.bias', 'model.10.crosstransformer.0.mlp_ir.2.weight', 'model.10.crosstransformer.0.mlp_ir.2.bias', 'model.10.crosstransformer.0.mlp.0.weight', 'model.10.crosstransformer.0.mlp.0.bias', 'model.10.crosstransformer.0.mlp.2.weight', 'model.10.crosstransformer.0.mlp.2.bias', 'model.10.crosstransformer.0.LN1.weight', 'model.10.crosstransformer.0.LN1.bias', 'model.10.crosstransformer.0.LN2.weight', 'model.10.crosstransformer.0.LN2.bias', 'model.10.crosstransformer.0.coefficient1.bias', 'model.10.crosstransformer.0.coefficient2.bias', 'model.10.crosstransformer.0.coefficient3.bias', 'model.10.crosstransformer.0.coefficient4.bias', 'model.10.crosstransformer.0.coefficient5.bias', 'model.10.crosstransformer.0.coefficient6.bias', 'model.10.crosstransformer.0.coefficient7.bias', 'model.10.crosstransformer.0.coefficient8.bias', 'model.10.conv1x1_out.conv.weight', 'model.10.conv1x1_out.bn.weight', 'model.10.conv1x1_out.bn.bias', 'model.10.conv1x1_out.bn.running_mean', 'model.10.conv1x1_out.bn.running_var', 'model.10.conv1x1_out.bn.num_batches_tracked', 'model.11.pos_emb_vis', 'model.11.pos_emb_ir', 'model.11.vis_coefficient.w1', 'model.11.vis_coefficient.w2', 'model.11.ir_coefficient.w1', 'model.11.ir_coefficient.w2', 'model.11.crosstransformer.0.ln_input.weight', 'model.11.crosstransformer.0.ln_input.bias', 'model.11.crosstransformer.0.ln_output.weight', 'model.11.crosstransformer.0.ln_output.bias', 'model.11.crosstransformer.0.crossatt.que_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.que_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.key_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.key_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.val_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.val_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.que_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.que_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.key_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.key_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.val_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.val_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.out_proj_vis.weight', 'model.11.crosstransformer.0.crossatt.out_proj_vis.bias', 'model.11.crosstransformer.0.crossatt.out_proj_ir.weight', 'model.11.crosstransformer.0.crossatt.out_proj_ir.bias', 'model.11.crosstransformer.0.crossatt.LN1.weight', 'model.11.crosstransformer.0.crossatt.LN1.bias', 'model.11.crosstransformer.0.crossatt.LN2.weight', 'model.11.crosstransformer.0.crossatt.LN2.bias', 'model.11.crosstransformer.0.mlp_vis.0.weight', 'model.11.crosstransformer.0.mlp_vis.0.bias', 'model.11.crosstransformer.0.mlp_vis.2.weight', 'model.11.crosstransformer.0.mlp_vis.2.bias', 'model.11.crosstransformer.0.mlp_ir.0.weight', 'model.11.crosstransformer.0.mlp_ir.0.bias', 'model.11.crosstransformer.0.mlp_ir.2.weight', 'model.11.crosstransformer.0.mlp_ir.2.bias', 'model.11.crosstransformer.0.mlp.0.weight', 'model.11.crosstransformer.0.mlp.0.bias', 'model.11.crosstransformer.0.mlp.2.weight', 'model.11.crosstransformer.0.mlp.2.bias', 'model.11.crosstransformer.0.LN1.weight', 'model.11.crosstransformer.0.LN1.bias', 'model.11.crosstransformer.0.LN2.weight', 'model.11.crosstransformer.0.LN2.bias', 'model.11.crosstransformer.0.coefficient1.bias', 'model.11.crosstransformer.0.coefficient2.bias', 'model.11.crosstransformer.0.coefficient3.bias', 'model.11.crosstransformer.0.coefficient4.bias', 'model.11.crosstransformer.0.coefficient5.bias', 'model.11.crosstransformer.0.coefficient6.bias', 'model.11.crosstransformer.0.coefficient7.bias', 'model.11.crosstransformer.0.coefficient8.bias', 'model.11.conv1x1_out.conv.weight', 'model.11.conv1x1_out.bn.weight', 'model.11.conv1x1_out.bn.bias', 'model.11.conv1x1_out.bn.running_mean', 'model.11.conv1x1_out.bn.running_var', 'model.11.conv1x1_out.bn.num_batches_tracked', 'model.12.pos_emb_vis', 'model.12.pos_emb_ir', 'model.12.vis_coefficient.w1', 'model.12.vis_coefficient.w2', 'model.12.ir_coefficient.w1', 'model.12.ir_coefficient.w2', 'model.12.crosstransformer.0.ln_input.weight', 'model.12.crosstransformer.0.ln_input.bias', 'model.12.crosstransformer.0.ln_output.weight', 'model.12.crosstransformer.0.ln_output.bias', 'model.12.crosstransformer.0.crossatt.que_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.que_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.key_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.key_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.val_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.val_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.que_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.que_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.key_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.key_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.val_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.val_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.out_proj_vis.weight', 'model.12.crosstransformer.0.crossatt.out_proj_vis.bias', 'model.12.crosstransformer.0.crossatt.out_proj_ir.weight', 'model.12.crosstransformer.0.crossatt.out_proj_ir.bias', 'model.12.crosstransformer.0.crossatt.LN1.weight', 'model.12.crosstransformer.0.crossatt.LN1.bias', 'model.12.crosstransformer.0.crossatt.LN2.weight', 'model.12.crosstransformer.0.crossatt.LN2.bias', 'model.12.crosstransformer.0.mlp_vis.0.weight', 'model.12.crosstransformer.0.mlp_vis.0.bias', 'model.12.crosstransformer.0.mlp_vis.2.weight', 'model.12.crosstransformer.0.mlp_vis.2.bias', 'model.12.crosstransformer.0.mlp_ir.0.weight', 'model.12.crosstransformer.0.mlp_ir.0.bias', 'model.12.crosstransformer.0.mlp_ir.2.weight', 'model.12.crosstransformer.0.mlp_ir.2.bias', 'model.12.crosstransformer.0.mlp.0.weight', 'model.12.crosstransformer.0.mlp.0.bias', 'model.12.crosstransformer.0.mlp.2.weight', 'model.12.crosstransformer.0.mlp.2.bias', 'model.12.crosstransformer.0.LN1.weight', 'model.12.crosstransformer.0.LN1.bias', 'model.12.crosstransformer.0.LN2.weight', 'model.12.crosstransformer.0.LN2.bias', 'model.12.crosstransformer.0.coefficient1.bias', 'model.12.crosstransformer.0.coefficient2.bias', 'model.12.crosstransformer.0.coefficient3.bias', 'model.12.crosstransformer.0.coefficient4.bias', 'model.12.crosstransformer.0.coefficient5.bias', 'model.12.crosstransformer.0.coefficient6.bias', 'model.12.crosstransformer.0.coefficient7.bias', 'model.12.crosstransformer.0.coefficient8.bias', 'model.12.conv1x1_out.conv.weight', 'model.12.conv1x1_out.bn.weight', 'model.12.conv1x1_out.bn.bias', 'model.12.conv1x1_out.bn.running_mean', 'model.12.conv1x1_out.bn.running_var', 'model.12.conv1x1_out.bn.num_batches_tracked', 'model.13.conv.weight', 'model.13.bn.weight', 'model.13.bn.bias', 'model.13.bn.running_mean', 'model.13.bn.running_var', 'model.13.bn.num_batches_tracked', 'model.16.cv1.conv.weight', 'model.16.cv1.bn.weight', 'model.16.cv1.bn.bias', 'model.16.cv1.bn.running_mean', 'model.16.cv1.bn.running_var', 'model.16.cv1.bn.num_batches_tracked', 'model.16.cv2.conv.weight', 'model.16.cv2.bn.weight', 'model.16.cv2.bn.bias', 'model.16.cv2.bn.running_mean', 'model.16.cv2.bn.running_var', 'model.16.cv2.bn.num_batches_tracked', 'model.16.cv3.conv.weight', 'model.16.cv3.bn.weight', 'model.16.cv3.bn.bias', 'model.16.cv3.bn.running_mean', 'model.16.cv3.bn.running_var', 'model.16.cv3.bn.num_batches_tracked', 'model.16.m.0.cv1.conv.weight', 'model.16.m.0.cv1.bn.weight', 'model.16.m.0.cv1.bn.bias', 'model.16.m.0.cv1.bn.running_mean', 'model.16.m.0.cv1.bn.running_var', 'model.16.m.0.cv1.bn.num_batches_tracked', 'model.16.m.0.cv2.conv.weight', 'model.16.m.0.cv2.bn.weight', 'model.16.m.0.cv2.bn.bias', 'model.16.m.0.cv2.bn.running_mean', 'model.16.m.0.cv2.bn.running_var', 'model.16.m.0.cv2.bn.num_batches_tracked', 'model.16.m.1.cv1.conv.weight', 'model.16.m.1.cv1.bn.weight', 'model.16.m.1.cv1.bn.bias', 'model.16.m.1.cv1.bn.running_mean', 'model.16.m.1.cv1.bn.running_var', 'model.16.m.1.cv1.bn.num_batches_tracked', 'model.16.m.1.cv2.conv.weight', 'model.16.m.1.cv2.bn.weight', 'model.16.m.1.cv2.bn.bias', 'model.16.m.1.cv2.bn.running_mean', 'model.16.m.1.cv2.bn.running_var', 'model.16.m.1.cv2.bn.num_batches_tracked', 'model.16.m.2.cv1.conv.weight', 'model.16.m.2.cv1.bn.weight', 'model.16.m.2.cv1.bn.bias', 'model.16.m.2.cv1.bn.running_mean', 'model.16.m.2.cv1.bn.running_var', 'model.16.m.2.cv1.bn.num_batches_tracked', 'model.16.m.2.cv2.conv.weight', 'model.16.m.2.cv2.bn.weight', 'model.16.m.2.cv2.bn.bias', 'model.16.m.2.cv2.bn.running_mean', 'model.16.m.2.cv2.bn.running_var', 'model.16.m.2.cv2.bn.num_batches_tracked', 'model.17.conv.weight', 'model.17.bn.weight', 'model.17.bn.bias', 'model.17.bn.running_mean', 'model.17.bn.running_var', 'model.17.bn.num_batches_tracked', 'model.20.cv1.conv.weight', 'model.20.cv1.bn.weight', 'model.20.cv1.bn.bias', 'model.20.cv1.bn.running_mean', 'model.20.cv1.bn.running_var', 'model.20.cv1.bn.num_batches_tracked', 'model.20.cv2.conv.weight', 'model.20.cv2.bn.weight', 'model.20.cv2.bn.bias', 'model.20.cv2.bn.running_mean', 'model.20.cv2.bn.running_var', 'model.20.cv2.bn.num_batches_tracked', 'model.20.cv3.conv.weight', 'model.20.cv3.bn.weight', 'model.20.cv3.bn.bias', 'model.20.cv3.bn.running_mean', 'model.20.cv3.bn.running_var', 'model.20.cv3.bn.num_batches_tracked', 'model.20.m.0.cv1.conv.weight', 'model.20.m.0.cv1.bn.weight', 'model.20.m.0.cv1.bn.bias', 'model.20.m.0.cv1.bn.running_mean', 'model.20.m.0.cv1.bn.running_var', 'model.20.m.0.cv1.bn.num_batches_tracked', 'model.20.m.0.cv2.conv.weight', 'model.20.m.0.cv2.bn.weight', 'model.20.m.0.cv2.bn.bias', 'model.20.m.0.cv2.bn.running_mean', 'model.20.m.0.cv2.bn.running_var', 'model.20.m.0.cv2.bn.num_batches_tracked', 'model.20.m.1.cv1.conv.weight', 'model.20.m.1.cv1.bn.weight', 'model.20.m.1.cv1.bn.bias', 'model.20.m.1.cv1.bn.running_mean', 'model.20.m.1.cv1.bn.running_var', 'model.20.m.1.cv1.bn.num_batches_tracked', 'model.20.m.1.cv2.conv.weight', 'model.20.m.1.cv2.bn.weight', 'model.20.m.1.cv2.bn.bias', 'model.20.m.1.cv2.bn.running_mean', 'model.20.m.1.cv2.bn.running_var', 'model.20.m.1.cv2.bn.num_batches_tracked', 'model.20.m.2.cv1.conv.weight', 'model.20.m.2.cv1.bn.weight', 'model.20.m.2.cv1.bn.bias', 'model.20.m.2.cv1.bn.running_mean', 'model.20.m.2.cv1.bn.running_var', 'model.20.m.2.cv1.bn.num_batches_tracked', 'model.20.m.2.cv2.conv.weight', 'model.20.m.2.cv2.bn.weight', 'model.20.m.2.cv2.bn.bias', 'model.20.m.2.cv2.bn.running_mean', 'model.20.m.2.cv2.bn.running_var', 'model.20.m.2.cv2.bn.num_batches_tracked', 'model.21.conv.weight', 'model.21.bn.weight', 'model.21.bn.bias', 'model.21.bn.running_mean', 'model.21.bn.running_var', 'model.21.bn.num_batches_tracked', 'model.23.cv1.conv.weight', 'model.23.cv1.bn.weight', 'model.23.cv1.bn.bias', 'model.23.cv1.bn.running_mean', 'model.23.cv1.bn.running_var', 'model.23.cv1.bn.num_batches_tracked', 'model.23.cv2.conv.weight', 'model.23.cv2.bn.weight', 'model.23.cv2.bn.bias', 'model.23.cv2.bn.running_mean', 'model.23.cv2.bn.running_var', 'model.23.cv2.bn.num_batches_tracked', 'model.23.cv3.conv.weight', 'model.23.cv3.bn.weight', 'model.23.cv3.bn.bias', 'model.23.cv3.bn.running_mean', 'model.23.cv3.bn.running_var', 'model.23.cv3.bn.num_batches_tracked', 'model.23.m.0.cv1.conv.weight', 'model.23.m.0.cv1.bn.weight', 'model.23.m.0.cv1.bn.bias', 'model.23.m.0.cv1.bn.running_mean', 'model.23.m.0.cv1.bn.running_var', 'model.23.m.0.cv1.bn.num_batches_tracked', 'model.23.m.0.cv2.conv.weight', 'model.23.m.0.cv2.bn.weight', 'model.23.m.0.cv2.bn.bias', 'model.23.m.0.cv2.bn.running_mean', 'model.23.m.0.cv2.bn.running_var', 'model.23.m.0.cv2.bn.num_batches_tracked', 'model.23.m.1.cv1.conv.weight', 'model.23.m.1.cv1.bn.weight', 'model.23.m.1.cv1.bn.bias', 'model.23.m.1.cv1.bn.running_mean', 'model.23.m.1.cv1.bn.running_var', 'model.23.m.1.cv1.bn.num_batches_tracked', 'model.23.m.1.cv2.conv.weight', 'model.23.m.1.cv2.bn.weight', 'model.23.m.1.cv2.bn.bias', 'model.23.m.1.cv2.bn.running_mean', 'model.23.m.1.cv2.bn.running_var', 'model.23.m.1.cv2.bn.num_batches_tracked', 'model.23.m.2.cv1.conv.weight', 'model.23.m.2.cv1.bn.weight', 'model.23.m.2.cv1.bn.bias', 'model.23.m.2.cv1.bn.running_mean', 'model.23.m.2.cv1.bn.running_var', 'model.23.m.2.cv1.bn.num_batches_tracked', 'model.23.m.2.cv2.conv.weight', 'model.23.m.2.cv2.bn.weight', 'model.23.m.2.cv2.bn.bias', 'model.23.m.2.cv2.bn.running_mean', 'model.23.m.2.cv2.bn.running_var', 'model.23.m.2.cv2.bn.num_batches_tracked', 'model.24.conv.weight', 'model.24.bn.weight', 'model.24.bn.bias', 'model.24.bn.running_mean', 'model.24.bn.running_var', 'model.24.bn.num_batches_tracked', 'model.26.cv1.conv.weight', 'model.26.cv1.bn.weight', 'model.26.cv1.bn.bias', 'model.26.cv1.bn.running_mean', 'model.26.cv1.bn.running_var', 'model.26.cv1.bn.num_batches_tracked', 'model.26.cv2.conv.weight', 'model.26.cv2.bn.weight', 'model.26.cv2.bn.bias', 'model.26.cv2.bn.running_mean', 'model.26.cv2.bn.running_var', 'model.26.cv2.bn.num_batches_tracked', 'model.26.cv3.conv.weight', 'model.26.cv3.bn.weight', 'model.26.cv3.bn.bias', 'model.26.cv3.bn.running_mean', 'model.26.cv3.bn.running_var', 'model.26.cv3.bn.num_batches_tracked', 'model.26.m.0.cv1.conv.weight', 'model.26.m.0.cv1.bn.weight', 'model.26.m.0.cv1.bn.bias', 'model.26.m.0.cv1.bn.running_mean', 'model.26.m.0.cv1.bn.running_var', 'model.26.m.0.cv1.bn.num_batches_tracked', 'model.26.m.0.cv2.conv.weight', 'model.26.m.0.cv2.bn.weight', 'model.26.m.0.cv2.bn.bias', 'model.26.m.0.cv2.bn.running_mean', 'model.26.m.0.cv2.bn.running_var', 'model.26.m.0.cv2.bn.num_batches_tracked', 'model.26.m.1.cv1.conv.weight', 'model.26.m.1.cv1.bn.weight', 'model.26.m.1.cv1.bn.bias', 'model.26.m.1.cv1.bn.running_mean', 'model.26.m.1.cv1.bn.running_var', 'model.26.m.1.cv1.bn.num_batches_tracked', 'model.26.m.1.cv2.conv.weight', 'model.26.m.1.cv2.bn.weight', 'model.26.m.1.cv2.bn.bias', 'model.26.m.1.cv2.bn.running_mean', 'model.26.m.1.cv2.bn.running_var', 'model.26.m.1.cv2.bn.num_batches_tracked', 'model.26.m.2.cv1.conv.weight', 'model.26.m.2.cv1.bn.weight', 'model.26.m.2.cv1.bn.bias', 'model.26.m.2.cv1.bn.running_mean', 'model.26.m.2.cv1.bn.running_var', 'model.26.m.2.cv1.bn.num_batches_tracked', 'model.26.m.2.cv2.conv.weight', 'model.26.m.2.cv2.bn.weight', 'model.26.m.2.cv2.bn.bias', 'model.26.m.2.cv2.bn.running_mean', 'model.26.m.2.cv2.bn.running_var', 'model.26.m.2.cv2.bn.num_batches_tracked', 'model.27.anchors', 'model.27.anchor_grid', 'model.27.m.0.weight', 'model.27.m.0.bias', 'model.27.m.1.weight', 'model.27.m.1.bias', 'model.27.m.2.weight', 'model.27.m.2.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Percorsi dei file\n",
    "pth1 = \"ICAFusion/icafusion_state_dict_AFTER_LOAD.pth\"\n",
    "\n",
    "\n",
    "# Carica\n",
    "d1 = torch.load(pth1, map_location='cpu')\n",
    "\n",
    "\n",
    "# Controlla le chiavi top-level\n",
    "print(d1.keys())    # Deve mostrare: dict_keys(['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00d7d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.mod1.encoder_q.0.conv1.weight                    <=> model.0.layer.0.weight                       \n",
      "    DenseDeCUR: [0.013406818732619286, 0.01471713650971651, -0.015291975811123848, -0.022917883470654488, -0.04084588959813118]\n",
      "    ICAfusion:  [0.013406818732619286, 0.01471713650971651, -0.015291975811123848, -0.022917883470654488, -0.04084588959813118]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.weight                      <=> model.0.layer.1.weight                       \n",
      "    DenseDeCUR: [0.23711252212524414, 0.2463444620370865, 0.33873045444488525, 0.3013361394405365, 0.14561231434345245]\n",
      "    ICAfusion:  [0.23711252212524414, 0.2463444620370865, 0.33873045444488525, 0.3013361394405365, 0.14561231434345245]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.bias                        <=> model.0.layer.1.bias                         \n",
      "    DenseDeCUR: [0.22382982075214386, 0.6235921382904053, 0.06124328449368477, 0.141941100358963, 0.1804104745388031]\n",
      "    ICAfusion:  [0.22382982075214386, 0.6235921382904053, 0.06124328449368477, 0.141941100358963, 0.1804104745388031]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.running_mean                <=> model.0.layer.1.running_mean                 \n",
      "    DenseDeCUR: [0.13234542310237885, 0.12470265477895737, 1.1110363006591797, -0.131943017244339, -0.070379339158535]\n",
      "    ICAfusion:  [0.13234542310237885, 0.12470265477895737, 1.1110363006591797, -0.131943017244339, -0.070379339158535]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.running_var                 <=> model.0.layer.1.running_var                  \n",
      "    DenseDeCUR: [0.7357009649276733, 1.1630104780197144, 1.7590787410736084, 3.7991750240325928, 0.4302455484867096]\n",
      "    ICAfusion:  [0.7357009649276733, 1.1630104780197144, 1.7590787410736084, 3.7991750240325928, 0.4302455484867096]\n",
      "\n",
      "module.mod1.encoder_q.0.bn1.num_batches_tracked         <=> model.0.layer.1.num_batches_tracked          \n",
      "    DenseDeCUR: [365]\n",
      "    ICAfusion:  [365]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.conv1.weight           <=> model.1.layer.0.conv1.weight                 \n",
      "    DenseDeCUR: [0.003525426611304283, 0.03986334428191185, -0.02479557693004608, -0.027785250917077065, 0.08889053761959076]\n",
      "    ICAfusion:  [0.003525426611304283, 0.03986334428191185, -0.02479557693004608, -0.027785250917077065, 0.08889053761959076]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.bn1.weight             <=> model.1.layer.0.bn1.weight                   \n",
      "    DenseDeCUR: [0.16457849740982056, 0.17449581623077393, 0.20205606520175934, 0.14830559492111206, 0.17417000234127045]\n",
      "    ICAfusion:  [0.16457849740982056, 0.17449581623077393, 0.20205606520175934, 0.14830559492111206, 0.17417000234127045]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.bn1.bias               <=> model.1.layer.0.bn1.bias                     \n",
      "    DenseDeCUR: [0.460193932056427, -0.03169002756476402, -0.06085263937711716, 0.11738814413547516, 0.25138407945632935]\n",
      "    ICAfusion:  [0.460193932056427, -0.03169002756476402, -0.06085263937711716, 0.11738814413547516, 0.25138407945632935]\n",
      "\n",
      "module.mod1.encoder_q.0.layer1.0.bn1.running_mean       <=> model.1.layer.0.bn1.running_mean             \n",
      "    DenseDeCUR: [-0.5390883088111877, -0.2985123097896576, 0.2766578197479248, -0.29329901933670044, -0.15242332220077515]\n",
      "    ICAfusion:  [-0.5390883088111877, -0.2985123097896576, 0.2766578197479248, -0.29329901933670044, -0.15242332220077515]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_densedecur_ica_comparison(densecur_model_state_dict, d1, mod=1, max_print=10)  # visible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876aa9c",
   "metadata": {},
   "source": [
    "```\n",
    "FINE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icafusion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
